{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "id": "1n96y39DGVbP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df2 = pd.read_csv(\"HI-Small_Trans.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "73LgHthuGVuC",
        "outputId": "d848cb86-06c3-4370-d895-2225488d914c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Timestamp</th>\n",
              "      <th>FromBank</th>\n",
              "      <th>Account</th>\n",
              "      <th>ToBank</th>\n",
              "      <th>ToAccount</th>\n",
              "      <th>Amount Received</th>\n",
              "      <th>Received Currency</th>\n",
              "      <th>Amount Paid</th>\n",
              "      <th>Payment Currency</th>\n",
              "      <th>Payment Format</th>\n",
              "      <th>Is Laundering</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9/1/2022 0:20</td>\n",
              "      <td>10</td>\n",
              "      <td>8000EBD30</td>\n",
              "      <td>10</td>\n",
              "      <td>8000EBD30</td>\n",
              "      <td>3697.34</td>\n",
              "      <td>US Dollar</td>\n",
              "      <td>3697.34</td>\n",
              "      <td>US Dollar</td>\n",
              "      <td>Reinvestment</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9/1/2022 0:20</td>\n",
              "      <td>3208</td>\n",
              "      <td>8000F4580</td>\n",
              "      <td>1</td>\n",
              "      <td>8000F5340</td>\n",
              "      <td>0.01</td>\n",
              "      <td>US Dollar</td>\n",
              "      <td>0.01</td>\n",
              "      <td>US Dollar</td>\n",
              "      <td>Cheque</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9/1/2022 0:00</td>\n",
              "      <td>3209</td>\n",
              "      <td>8000F4670</td>\n",
              "      <td>3209</td>\n",
              "      <td>8000F4670</td>\n",
              "      <td>14675.57</td>\n",
              "      <td>US Dollar</td>\n",
              "      <td>14675.57</td>\n",
              "      <td>US Dollar</td>\n",
              "      <td>Reinvestment</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9/1/2022 0:02</td>\n",
              "      <td>12</td>\n",
              "      <td>8000F5030</td>\n",
              "      <td>12</td>\n",
              "      <td>8000F5030</td>\n",
              "      <td>2806.97</td>\n",
              "      <td>US Dollar</td>\n",
              "      <td>2806.97</td>\n",
              "      <td>US Dollar</td>\n",
              "      <td>Reinvestment</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9/1/2022 0:06</td>\n",
              "      <td>10</td>\n",
              "      <td>8000F5200</td>\n",
              "      <td>10</td>\n",
              "      <td>8000F5200</td>\n",
              "      <td>36682.97</td>\n",
              "      <td>US Dollar</td>\n",
              "      <td>36682.97</td>\n",
              "      <td>US Dollar</td>\n",
              "      <td>Reinvestment</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Timestamp  FromBank    Account  ToBank  ToAccount  Amount Received  \\\n",
              "0  9/1/2022 0:20        10  8000EBD30      10  8000EBD30          3697.34   \n",
              "1  9/1/2022 0:20      3208  8000F4580       1  8000F5340             0.01   \n",
              "2  9/1/2022 0:00      3209  8000F4670    3209  8000F4670         14675.57   \n",
              "3  9/1/2022 0:02        12  8000F5030      12  8000F5030          2806.97   \n",
              "4  9/1/2022 0:06        10  8000F5200      10  8000F5200         36682.97   \n",
              "\n",
              "  Received Currency  Amount Paid Payment Currency Payment Format  \\\n",
              "0         US Dollar      3697.34        US Dollar   Reinvestment   \n",
              "1         US Dollar         0.01        US Dollar         Cheque   \n",
              "2         US Dollar     14675.57        US Dollar   Reinvestment   \n",
              "3         US Dollar      2806.97        US Dollar   Reinvestment   \n",
              "4         US Dollar     36682.97        US Dollar   Reinvestment   \n",
              "\n",
              "   Is Laundering  \n",
              "0              0  \n",
              "1              0  \n",
              "2              0  \n",
              "3              0  \n",
              "4              0  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xHnZ-9YaVbGV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1qdTqFUZxk-",
        "outputId": "5daad7c9-fb23-4222-d3a2-2aabba73cd7d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Timestamp', 'FromBank', 'Account', 'ToBank', 'ToAccount',\n",
              "       'Amount Received', 'Received Currency', 'Amount Paid',\n",
              "       'Payment Currency', 'Payment Format', 'Is Laundering'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RFtzjMODVbJc"
      },
      "outputs": [],
      "source": [
        "# --------------------------- Data Preprocessing --------------------------- #\n",
        "# Convert 'Timestamp' to datetime\n",
        "df2[\"Timestamp\"] = pd.to_datetime(df2[\"Timestamp\"])\n",
        "df = df2.sort_values(by=\"Timestamp\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "QAvia9CHVbMT",
        "outputId": "d6ecc683-75c2-4f71-c135-137007d9249d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Timestamp</th>\n",
              "      <th>FromBank</th>\n",
              "      <th>Account</th>\n",
              "      <th>ToBank</th>\n",
              "      <th>ToAccount</th>\n",
              "      <th>Amount Received</th>\n",
              "      <th>Received Currency</th>\n",
              "      <th>Amount Paid</th>\n",
              "      <th>Payment Currency</th>\n",
              "      <th>Payment Format</th>\n",
              "      <th>Is Laundering</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14582</th>\n",
              "      <td>2022-09-01</td>\n",
              "      <td>31489</td>\n",
              "      <td>801917BF0</td>\n",
              "      <td>31489</td>\n",
              "      <td>801917BF0</td>\n",
              "      <td>1305.63</td>\n",
              "      <td>US Dollar</td>\n",
              "      <td>1305.63</td>\n",
              "      <td>US Dollar</td>\n",
              "      <td>Reinvestment</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14870</th>\n",
              "      <td>2022-09-01</td>\n",
              "      <td>21940</td>\n",
              "      <td>80197A4D0</td>\n",
              "      <td>21940</td>\n",
              "      <td>80197A4D0</td>\n",
              "      <td>456281.58</td>\n",
              "      <td>US Dollar</td>\n",
              "      <td>456281.58</td>\n",
              "      <td>US Dollar</td>\n",
              "      <td>Reinvestment</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109034</th>\n",
              "      <td>2022-09-01</td>\n",
              "      <td>245993</td>\n",
              "      <td>812456260</td>\n",
              "      <td>245993</td>\n",
              "      <td>812456260</td>\n",
              "      <td>956.94</td>\n",
              "      <td>US Dollar</td>\n",
              "      <td>956.94</td>\n",
              "      <td>US Dollar</td>\n",
              "      <td>Reinvestment</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120172</th>\n",
              "      <td>2022-09-01</td>\n",
              "      <td>27637</td>\n",
              "      <td>813F86850</td>\n",
              "      <td>27637</td>\n",
              "      <td>813F86850</td>\n",
              "      <td>9.26</td>\n",
              "      <td>US Dollar</td>\n",
              "      <td>9.26</td>\n",
              "      <td>US Dollar</td>\n",
              "      <td>Reinvestment</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58764</th>\n",
              "      <td>2022-09-01</td>\n",
              "      <td>17732</td>\n",
              "      <td>807AF6230</td>\n",
              "      <td>8623</td>\n",
              "      <td>808FE16B0</td>\n",
              "      <td>25340.11</td>\n",
              "      <td>US Dollar</td>\n",
              "      <td>25340.11</td>\n",
              "      <td>US Dollar</td>\n",
              "      <td>Cheque</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Timestamp  FromBank    Account  ToBank  ToAccount  Amount Received  \\\n",
              "14582  2022-09-01     31489  801917BF0   31489  801917BF0          1305.63   \n",
              "14870  2022-09-01     21940  80197A4D0   21940  80197A4D0        456281.58   \n",
              "109034 2022-09-01    245993  812456260  245993  812456260           956.94   \n",
              "120172 2022-09-01     27637  813F86850   27637  813F86850             9.26   \n",
              "58764  2022-09-01     17732  807AF6230    8623  808FE16B0         25340.11   \n",
              "\n",
              "       Received Currency  Amount Paid Payment Currency Payment Format  \\\n",
              "14582          US Dollar      1305.63        US Dollar   Reinvestment   \n",
              "14870          US Dollar    456281.58        US Dollar   Reinvestment   \n",
              "109034         US Dollar       956.94        US Dollar   Reinvestment   \n",
              "120172         US Dollar         9.26        US Dollar   Reinvestment   \n",
              "58764          US Dollar     25340.11        US Dollar         Cheque   \n",
              "\n",
              "        Is Laundering  \n",
              "14582               0  \n",
              "14870               0  \n",
              "109034              0  \n",
              "120172              0  \n",
              "58764               0  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "LBALRWd3VbQN"
      },
      "outputs": [],
      "source": [
        "# Rename columns for better handling\n",
        "df.rename(columns={\n",
        "    \"FromBank\": \"Sender_Bank\",\n",
        "    \"Account\": \"Sender_Account\",\n",
        "    \"ToBank\": \"Receiver_Bank\",\n",
        "    \"ToAccount\": \"Receiver_Account\",\n",
        "    \"Amount Received\": \"Amount_Received\",\n",
        "    \"Received Currency\": \"Receiving_Currency\",\n",
        "    \"Amount Paid\": \"Amount_Paid\",\n",
        "    \"Payment Currency\": \"Payment_Currency\",\n",
        "    \"Payment Format\": \"Payment_Format\",\n",
        "    \"Is Laundering\": \"Is_Laundering\"\n",
        "}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7ZqerReai6q",
        "outputId": "cb4c7f93-a686-4268-aabe-4ec0b9b62085"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\1522723957.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\1522723957.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\1522723957.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].mode()[0], inplace=True)\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\1522723957.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\1522723957.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].mode()[0], inplace=True)\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\1522723957.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\1522723957.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].mode()[0], inplace=True)\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\1522723957.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\1522723957.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].mode()[0], inplace=True)\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\1522723957.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n"
          ]
        }
      ],
      "source": [
        "# Fill missing values (categorical: mode, numerical: median)\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == \"object\":\n",
        "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
        "    else:\n",
        "        df[col].fillna(df[col].median(), inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "7JxjW729ai9P"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "# Encoding categorical variables\n",
        "categorical_cols = [\"Sender_Bank\", \"Receiver_Bank\", \"Receiving_Currency\", \"Payment_Currency\", \"Payment_Format\"]\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofW0SUIxajAD",
        "outputId": "2e9b94a9-65c0-40ee-f05a-a3c9abf3cd30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Timestamp             0\n",
            "Sender_Bank           0\n",
            "Sender_Account        0\n",
            "Receiver_Bank         0\n",
            "Receiver_Account      0\n",
            "Amount_Received       0\n",
            "Receiving_Currency    0\n",
            "Amount_Paid           0\n",
            "Payment_Currency      0\n",
            "Payment_Format        0\n",
            "Is_Laundering         0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JO0gDnruajCp",
        "outputId": "b6c51945-e825-4e69-e98e-dec6439684f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Amount Received equals to Amount Paid:\n",
            "False\n",
            "Receiving Currency equals to Payment Currency:\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "print('Amount Received equals to Amount Paid:')\n",
        "print(df['Amount_Received'].equals(df['Amount_Paid']))\n",
        "print('Receiving Currency equals to Payment Currency:')\n",
        "print(df['Receiving_Currency'].equals(df['Payment_Currency']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNX2RTgJajH4",
        "outputId": "1ff1ad48-fde4-4594-a914-1344e5e8d26f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3999006248.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[\"Transaction_Difference_Percentage\"].fillna(0, inplace=True)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "# --------------------------- Feature Engineering --------------------------- #\n",
        "# 1️⃣ Transaction-Based Features\n",
        "#transaction_amount_log: Log transformation for better scaling\n",
        "#rolling_avg_amount_7d: Average transaction amount over the last 7 days\n",
        "#rolling_std_amount_7d: Standard deviation of transactions over the last 7 days\n",
        "\n",
        "df[\"Transaction_Difference\"] = df[\"Amount_Paid\"] - df[\"Amount_Received\"]\n",
        "df[\"Transaction_Difference_Percentage\"] = df[\"Transaction_Difference\"] / df[\"Amount_Paid\"]\n",
        "df[\"Transaction_Difference_Percentage\"].fillna(0, inplace=True)\n",
        "\n",
        "# Log transformation to handle skewness in amounts\n",
        "df[\"log_Amount_Received\"] = np.log1p(df[\"Amount_Received\"])\n",
        "df[\"log_Amount_Paid\"] = np.log1p(df[\"Amount_Paid\"])\n",
        "\n",
        "# Rolling statistics (last 7 days)\n",
        "df[\"Rolling_Mean_Amount_7D\"] = df.groupby(\"Sender_Account\")[\"Amount_Paid\"].transform(\n",
        "    lambda x: x.rolling(7, min_periods=1).mean()\n",
        ")\n",
        "df[\"Rolling_Std_Amount_7D\"] = df.groupby(\"Sender_Account\")[\"Amount_Paid\"].transform(\n",
        "    lambda x: x.rolling(7, min_periods=1).std()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "elEPQasac7lN"
      },
      "outputs": [],
      "source": [
        "# 2️⃣ Time-Based Features\n",
        "#hour_of_transaction: Transaction hour (to detect unusual times)\n",
        "#day_of_week: Day of the week (0=Monday, 6=Sunday)\n",
        "#is_weekend: Whether the transaction happened on a weekend\n",
        "\n",
        "df[\"Hour\"] = df[\"Timestamp\"].dt.hour\n",
        "df[\"Day_of_Week\"] = df[\"Timestamp\"].dt.dayofweek\n",
        "df[\"Is_Weekend\"] = df[\"Day_of_Week\"].apply(lambda x: 1 if x >= 5 else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "3oN0YbJ0c7ph",
        "outputId": "34bfc91f-35b9-45ad-e91f-7f0e56559c7b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Timestamp</th>\n",
              "      <th>Sender_Bank</th>\n",
              "      <th>Sender_Account</th>\n",
              "      <th>Receiver_Bank</th>\n",
              "      <th>Receiver_Account</th>\n",
              "      <th>Amount_Received</th>\n",
              "      <th>Receiving_Currency</th>\n",
              "      <th>Amount_Paid</th>\n",
              "      <th>Payment_Currency</th>\n",
              "      <th>Payment_Format</th>\n",
              "      <th>Is_Laundering</th>\n",
              "      <th>Transaction_Difference</th>\n",
              "      <th>Transaction_Difference_Percentage</th>\n",
              "      <th>log_Amount_Received</th>\n",
              "      <th>log_Amount_Paid</th>\n",
              "      <th>Rolling_Mean_Amount_7D</th>\n",
              "      <th>Rolling_Std_Amount_7D</th>\n",
              "      <th>Hour</th>\n",
              "      <th>Day_of_Week</th>\n",
              "      <th>Is_Weekend</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14582</th>\n",
              "      <td>2022-09-01</td>\n",
              "      <td>1056</td>\n",
              "      <td>801917BF0</td>\n",
              "      <td>952</td>\n",
              "      <td>801917BF0</td>\n",
              "      <td>1305.63</td>\n",
              "      <td>12</td>\n",
              "      <td>1305.63</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.175207</td>\n",
              "      <td>7.175207</td>\n",
              "      <td>1305.63</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14870</th>\n",
              "      <td>2022-09-01</td>\n",
              "      <td>702</td>\n",
              "      <td>80197A4D0</td>\n",
              "      <td>640</td>\n",
              "      <td>80197A4D0</td>\n",
              "      <td>456281.58</td>\n",
              "      <td>12</td>\n",
              "      <td>456281.58</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.030868</td>\n",
              "      <td>13.030868</td>\n",
              "      <td>456281.58</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109034</th>\n",
              "      <td>2022-09-01</td>\n",
              "      <td>4939</td>\n",
              "      <td>812456260</td>\n",
              "      <td>4231</td>\n",
              "      <td>812456260</td>\n",
              "      <td>956.94</td>\n",
              "      <td>12</td>\n",
              "      <td>956.94</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.864785</td>\n",
              "      <td>6.864785</td>\n",
              "      <td>956.94</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120172</th>\n",
              "      <td>2022-09-01</td>\n",
              "      <td>807</td>\n",
              "      <td>813F86850</td>\n",
              "      <td>745</td>\n",
              "      <td>813F86850</td>\n",
              "      <td>9.26</td>\n",
              "      <td>12</td>\n",
              "      <td>9.26</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.328253</td>\n",
              "      <td>2.328253</td>\n",
              "      <td>9.26</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58764</th>\n",
              "      <td>2022-09-01</td>\n",
              "      <td>622</td>\n",
              "      <td>807AF6230</td>\n",
              "      <td>372</td>\n",
              "      <td>808FE16B0</td>\n",
              "      <td>25340.11</td>\n",
              "      <td>12</td>\n",
              "      <td>25340.11</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.140183</td>\n",
              "      <td>10.140183</td>\n",
              "      <td>25340.11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Timestamp  Sender_Bank Sender_Account  Receiver_Bank Receiver_Account  \\\n",
              "14582  2022-09-01         1056      801917BF0            952        801917BF0   \n",
              "14870  2022-09-01          702      80197A4D0            640        80197A4D0   \n",
              "109034 2022-09-01         4939      812456260           4231        812456260   \n",
              "120172 2022-09-01          807      813F86850            745        813F86850   \n",
              "58764  2022-09-01          622      807AF6230            372        808FE16B0   \n",
              "\n",
              "        Amount_Received  Receiving_Currency  Amount_Paid  Payment_Currency  \\\n",
              "14582           1305.63                  12      1305.63                12   \n",
              "14870         456281.58                  12    456281.58                12   \n",
              "109034           956.94                  12       956.94                12   \n",
              "120172             9.26                  12         9.26                12   \n",
              "58764          25340.11                  12     25340.11                12   \n",
              "\n",
              "        Payment_Format  Is_Laundering  Transaction_Difference  \\\n",
              "14582                5              0                     0.0   \n",
              "14870                5              0                     0.0   \n",
              "109034               5              0                     0.0   \n",
              "120172               5              0                     0.0   \n",
              "58764                3              0                     0.0   \n",
              "\n",
              "        Transaction_Difference_Percentage  log_Amount_Received  \\\n",
              "14582                                 0.0             7.175207   \n",
              "14870                                 0.0            13.030868   \n",
              "109034                                0.0             6.864785   \n",
              "120172                                0.0             2.328253   \n",
              "58764                                 0.0            10.140183   \n",
              "\n",
              "        log_Amount_Paid  Rolling_Mean_Amount_7D  Rolling_Std_Amount_7D  Hour  \\\n",
              "14582          7.175207                 1305.63                    NaN     0   \n",
              "14870         13.030868               456281.58                    NaN     0   \n",
              "109034         6.864785                  956.94                    NaN     0   \n",
              "120172         2.328253                    9.26                    NaN     0   \n",
              "58764         10.140183                25340.11                    NaN     0   \n",
              "\n",
              "        Day_of_Week  Is_Weekend  \n",
              "14582             3           0  \n",
              "14870             3           0  \n",
              "109034            3           0  \n",
              "120172            3           0  \n",
              "58764             3           0  "
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ys6sXzApc7r3"
      },
      "outputs": [],
      "source": [
        "# 3️⃣ Behavior-Based Features\n",
        "#num_transactions_30d: Number of transactions in the last 30 days\n",
        "#avg_transaction_amount_30d: Mean transaction amount over 30 days\n",
        "\n",
        "df[\"Num_Transactions_30D\"] = df.groupby(\"Sender_Account\")[\"Amount_Paid\"].transform(\n",
        "    lambda x: x.rolling(30, min_periods=1).count()\n",
        ")\n",
        "df[\"Avg_Transaction_30D\"] = df.groupby(\"Sender_Account\")[\"Amount_Paid\"].transform(\n",
        "    lambda x: x.rolling(30, min_periods=1).mean()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ELhacAgpc7u-"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "# 4️⃣ Network-Based Features (Using Graphs)\n",
        "#degree_centrality: Number of connections an account has\n",
        "#pagerank_score: Importance of an account in the transaction network\n",
        "\n",
        "G = nx.from_pandas_edgelist(df, source=\"Sender_Account\", target=\"Receiver_Account\")\n",
        "\n",
        "# Degree centrality (number of connections)\n",
        "degree_centrality = nx.degree_centrality(G)\n",
        "df[\"Degree_Centrality\"] = df[\"Sender_Account\"].map(degree_centrality)\n",
        "\n",
        "# PageRank Score\n",
        "pagerank = nx.pagerank(G)\n",
        "df[\"PageRank_Score\"] = df[\"Sender_Account\"].map(pagerank)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Qr7ER1CVc7x2"
      },
      "outputs": [],
      "source": [
        "# 5️⃣ Currency-Based Features\n",
        "#cross_country_transaction: Flag for international transactions\n",
        "\n",
        "df[\"Cross_Currency_Transaction\"] = df.apply(lambda x: 1 if x[\"Receiving_Currency\"] != x[\"Payment_Currency\"] else 0, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "grhBzz71c71Q"
      },
      "outputs": [],
      "source": [
        "# 6️⃣ Scaling Numerical Features\n",
        "scaler = StandardScaler()\n",
        "num_features = [\n",
        "    \"Amount_Received\", \"Amount_Paid\", \"Transaction_Difference\", \"Transaction_Difference_Percentage\",\n",
        "    \"Rolling_Mean_Amount_7D\", \"Rolling_Std_Amount_7D\", \"Num_Transactions_30D\",\n",
        "    \"Degree_Centrality\", \"PageRank_Score\"\n",
        "]\n",
        "df[num_features] = scaler.fit_transform(df[num_features])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41E1JnLSc76M",
        "outputId": "223c5f0c-86ef-4a52-ea8d-66be9cb374b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data preprocessing and feature engineering completed!\n"
          ]
        }
      ],
      "source": [
        "# Save processed data\n",
        "df.to_csv(\"IBM_AML_Preprocessed.csv\", index=False)\n",
        "\n",
        "print(\"Data preprocessing and feature engineering completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "7SCE8FqvobgB",
        "outputId": "663b9ce7-2ed6-4426-922f-65f82b704c3f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAx8AAAHWCAYAAAAW3DTwAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAANT9JREFUeJzt3QecHVXdP/6TEAgESOgQem8iXZDOA0gVERCxo6JIUUAUu4BKUwRFVFAUUUFAFBB4RECkKB1pSpPQjFSpCR2S+b2+5/+ffe7e3C13sznb3u/Xa7PZe+dOOzNz5zPnzJlRVVVVCQAAYBYbPasnAAAAEIQPAACgCOEDAAAoQvgAAACKED4AAIAihA8AAKAI4QMAAChC+AAAAIoQPgAAgCKEDxihPvrRj6Zll112oGeDmbTlllvmnxJGjRqVjjjiiI6/4//x2tNPP11k+rG9xnY7UL7zne+kVVddNU2fPj2NBHX5jvTjYvN2X8qXvvSltOGGGxafLsxqwgfDWnxp9ObnqquuSsPRY489lr80b7/99jQY3XPPPXn9zznnnOn5559Pw811112X139vly1OfBq3y3nmmSctv/zy6T3veU/6/e9/328nve3OV0mDdd6mTJmSvv3tb6cvfvGLafTo//vqbCyvMWPGpAUWWCCtt9566aCDDkp33333TE3z6KOPThdccEGalV5++eW8vgfrMfDiiy9O22+/fVpwwQXzcWLllVdOn//859MzzzwzbI+LtYMPPjjdcccd6cILLxzoWYF+NaZ/RweDy69//etOf//qV79Kl19++Qyvr7baamk4ii/Zb3zjG/lK3tprr93pvVNPPXXAr+CeccYZabHFFkvPPfdc+t3vfpc+8YlPpOEkTqRj/UeomG+++Xr1mbFjx6af/exn+f+vvPJKeuSRR9JFF12UA0jUcPzhD39I48eP7xj+sssuKzJf9fzECfas1N283XfffZ1O/Es67bTT0ptvvpne//73z/DeO97xjvSRj3wkVVWVXnjhhXzC+Mtf/jL9+Mc/zoHlkEMO6XP4iHJ/97vfnWZl+Ij1HZpr0L72ta/lq+8DJULG8ccfn9Zaa60c+iLY3XrrremHP/xhOvvss9MVV1yRVllllX49Lg7Udt9KHBt32WWX9N3vfje9613vKj59mFWED4a1D33oQ53+vuGGG3L4aH691RfyuHHj0nA2++yzD+j040TtN7/5TfrABz6QHnrooXTmmWcOu/DRF3GS07x9HnnkkenYY49NX/7yl9MnP/nJdM4553S8N8ccc8zS+YmA+vrrr+erzvEzkCKYDZRf/OIX+QSw1TqIq/HNZRbltfPOO6fPfe5zuanWjjvumIbitjgQJ93hrLPOysFjzz33zMeG2WabreO9CKb/8z//k/bYY48cRmb1PPbndv/qq6/mfba3Ifq9731vXs4HH3ww14LCsFDBCHLAAQdUzZv9FltsUb3lLW+pbrnllmqzzTar5pprruqggw7K711wwQXVjjvuWE2cOLGaY445quWXX7765je/Wb355pstx3HXXXdVW265ZR7H4osvXn3729+eYR5+8IMfVKuvvnoeZr755qvWW2+96swzz+x4/+GHH67222+/auWVV67mnHPOaoEFFqje8573VA899NAM43ruueeqgw8+uFpmmWXy/C2xxBLVhz/84eq///1vdeWVV+Zlbf75xS9+kT+711575c81evHFF6tDDjmkWnLJJfP4Yh6OO+64avr06Z2Gi/HEujz//PPzcsewsUyXXHJJr8vir3/9ax7PTTfdVJ1zzjnV6NGjq8mTJ88wXMzjTjvtlJcn1lWskzXWWCP/HX7/+9/nv8eOHVutu+661a233jrDOK644opq0003rcaNG1dNmDChete73lXdfffdnYZptT7C4YcfPsM205vlrz/X/NOqHBvnYe655+7y/W233bYaNWpUdd9993Xa9uKnt9tYT/NVL9sZZ5yRxzFmzJi8nPV78fnmZbznnnuqPfbYo5p33nnz9nrggQdWr7zySsdwMe7Gba95Xdbj7GneonxiHTV64IEH8v4x//zz5+XdcMMNq4svvrjTMPW+ENvZkUcemfeT2F622mqr6v7776968uCDD+bPn3766S3nP9ZXK4888khefxtvvHGn11999dXqsMMOq1ZYYYW87cT+duihh+bXG8fb/NO47P/5z3+qj33sY9UiiyzSsf39/Oc/n2Eeohxiva600kp5mRdbbLFq1113rSZNmtRRLs0/zeXR132/3mdjunHsPOWUU1qOs5VVVlkll+kLL7zQ8v1vfOMbeTxnnXVWx2utto/mfaQvx8Xm7b6367+eVszjV7/61fydEPtvHLdff/316ogjjqhWXHHFvH5iv9lkk02qyy67rNM4nn/++fyZE044ocd1BkOFmg9IKbcf3mGHHdL73ve+fAVz0UUXza+ffvrpud19NJuI33/5y1/SYYcdltt/H3fccZ3GEU2Hom3ybrvtlq9WRTOiaCrw1re+NY+7bup04IEH5qYU0SY8roLdeeed6cYbb8w1AOHmm2/OTU9iXpZccsn08MMPp5NPPjk3iYg25HWNzIsvvpg222yzfN/Exz/+8bTuuuvmG3+jffB//vOf3JTsm9/8Zp7fffbZJw8bNt5445brIL5j48rulVdemfbee+/cHOHSSy9Nhx56aHr00UfT9773vU7D/+1vf0vnnXde2n///dO8886bfvCDH6Tdd989/fvf/87ts3sSVzNXWGGF9La3vS2tscYaebniamdMr9mkSZPy+vnUpz6VyyeaIcRV5VNOOSV95StfyfMQjjnmmLzuG5vn/PnPf87rP64aRjvvaEJx0kknpU022SRfNe3rTfc9LX9sB//617/yMsW6W2ihhfLnFl544dRXH/7wh3Mzq6i9i6vtrfS0jfVmvmI7/+1vf5s+/elP5/d7WkexzmOYWP9RuxjrIvaHaObYjnbX2ZNPPpm356ipjGWO9R7NnWI7jv1v1113naE2IraLaM4TzaPiBvIPfvCDed10J/bHEPtYO5Zeeum0xRZb5H0qjhnRXC5qkmL+YvuJ/TL203/84x95eWPZ63s8omlo1ARusMEGebgQ+0u93G9/+9vzfSZRRrF+LrnkkrzfxnTiXoEwbdq09M53vjM3T4rjSWwPU6dOzdvPP//5z7TNNtvkY8t+++2X11Ws/7Dmmmt2u1y92fdvu+22fDycOHFibuIU8xLHo95s//fff3/eh6OGo7GJYaNo5nb44Yfne0Ji2Xqr3eNiK71d/7VvfetbubYjtrvXXnst/z+ORbG/1GUcn7vlllvyMSma8dUmTJiQy/3aa69Nn/3sZ3s9jzCoDXT6gcFQ8xGvxVW5Zi+//PIMr33qU5/KV9Abr1LW4/jVr37V8dprr72WrzLuvvvuHa/tsssu+Wphd1pN8/rrr59h/HHlNF4777zzZhi+rqm4+eabu7zi3HyFL2p5Yti4MtworirHlbe4UlqL4eJqX+Nrd9xxR379pJNOqnoSV/0WXHDBfDWw9oEPfKBaa621Zhg25jHGe91113W8dumll+bX4kp3XF2u/eQnP8mv17UiYe21185XJ5955plO8xo1LR/5yEe6XB+1rq7+9mb5o9aop9qOdmo+brvttjy+z372s13WfPRmG+tuvuL1WDdRi9fqvVY1H1GT1Gj//ffPr8c6aafmo6d5a76yHbV+MWzUotWmTp1aLbfcctWyyy5bTZs2rdMV6NVWWy3vl7UTTzwxv/6Pf/yj2/X1ta99LQ8X426n5iNELWrjuvj1r3+d12/jPIc4/sRw1157bcdrsS20upK/995759rYp59+utPr73vf+3LNXn0MOe200/I4W101r48RUUva6sr+zG77O++8cz5OPvroox2vRS1T1AT1dOpRH4u+973vdTvc+PHjc21nOzUf7R4X62VuXD+9Xf/1dhe1Ps3H9TjWRY1ub0SNZ2y7MFzo7Qr+/7bkH/vYx2Z4fa655ur4f1wxjJqFuFIWV1rvvffeTsNGzUhju++4uhVXtKKtbi1uoI1aiajd6ErjNN94441cK7Piiivmz8ZVsVr0fhQ3YjZf3Q196R7zj3/8Y25XHVeQG0Wb9fj+jSt7jeKqaX0ltr5aGlcpG5e3KzGuWK7Gm3fj/3Gj7l133TXD8KuvvnraaKONOv6uu5/caqut8tXl5tfreXj88cdzjzZxBTVuVm2c17i6GMvcVzOz/H0V21i9LXalN9tYT+Jqfazz3jrggAM6/f2Zz3wm/56Z9dsbMf7YxzbddNNO6yiuaEeNYXNvU7GPN94jU1/17qnMYluN+wrq9T8zZXbuuefmq+9xH0gcT+qf2JZD1JJ0J/bF2Pej5i/+3ziO7bbbLtfo1MeJGC5qj+ryaDQzXej2tO1HLUfUOMaN8osvvnjHcHEcq2uBu1Ovq6hV6U68HzUGJbWz/mt77bVXp+N6vZ/GsS5qeXoy//zzF+vOGkoQPiCltMQSS7S8cTe+HOLkPqq+48s1qtfrgBFfMo2iiVTzF3p8aUTzk1o0w4qTkThhWmmllfJJW1SnN4pmQdEkYKmllsqhKE4eYrrR9WjjNB944IHcXKm/RK9KcaLQ/IVf9wQW7zdqPOnvanm76+VqueWWy8sXTariJ05moulVNMdq1jytKI8Q66jV6/U81PPcqkecWK74Qn/ppZdSX8zM8vdVNLXr6aSsN9tYT6Js2hHTaRRlGc2bIgDMSlG+XZVt/X53ZRblFUqWWZxsxnEl9unGn7oZ3VNPPdXt+P773//mY8FPf/rTGcZRX0CpxxHHiFg//X1Ddk/bfkw/jmMRNpq1eq1Zva66C9n1+z0FlP7Wzvrvbn+Kpl8xnij3aJobzU2jeWQrEXJG2vNWGN7c8wFNtQ21+GKIK8AROuKLIk6ooteTuKoVJ3jN3dQ29sbS6P+rtf+/k6JoyxztlP/0pz/lK2jRHWeEjbq7y7hKGT3rRLvhuNofJ9TxxRPtmge6a9x2l7eVuFIZXcfGvQjNJ60hesA66qijOn3ZdjWtvs5DK119ucdV3Fk97d6Kdvo9ncD1Zhvry/4wM+uy3XU7q/S1zOI+huhmty8nu1FmMd36BDT24TjZPOGEE1oO3xyom9XHgLgIElfUW+npno2ZNau3/To8dnUyXgfLOJY01tB1t511Nc/t6sv6b7U/bb755jkcRtfZcR9XdK8d9/3EfWzNvf5FqKvvf4LhQPiALsRDt6K5RdxYGV8UtegWdmbMPffcufvI+IkuTOMmzzjZjm5UI9zEjbLxpRbdTNbiRL35oWsRhuqT0a60c7VsmWWWyU0lmk+w6uZl8X5/iPUZyxM3ujZ/ocZJczxbIK7UNzal6at6nmO8zWK5YvpRHvWV21YPtmu+et6O/r5aGTchxzgbb0jtyzbW3/MVV/Mbr+5GTVacpNU3qtc1DM3rt9W6bXeb7aps6/f7QzSRqvf9dk7s4wbsq6++Ol9EqPep2G+jeeHWW2/d47K2ej+usMe44oQ6mj91J6YVN9NH882uutaeFVfUF1lkkbydxXbQrNVrzaI2IH7i5vsTTzyxZeCrOzOIG+pr3e3Djd3Uzswyt7P+exJNQaO2JH6ihiy+Z+JG9ObwEdtdNLGF4UKzK+hCfaWs8WpenMjFVeS+an4qbzT1iit3MY04Qain23wFMXpnar5KHL3LxEnM+eefP8N06s/XJ9a9eVp0PIcgphEP8GoUV+Piy7o3bbV7I5pcxYnAvvvum3tkavyJ3mCiyVCrpld9ET3tRK9d0QNS4zqI0BZXGxufvRAnatGsrfFqa9wz0mr99lY7678n0VNTzHMEilY1Ru1sY/05X+FHP/rRDNtrqLeZqD2MoHfNNdd0Gq7VvtTuNnvTTTel66+/vuO1aEYXTWIi+LRz30p36vuNojei3nr22WfzfUyxT331q1/t1DNY9B4XvZI1i6ZKjc0AY100r4c4PsS+HzVarS4+RLOgWgwXTQub9+nGY0Tde15/PlE+5jFOzCM8xAP9GoNH871jXYmaurjiH8eJ5mPf3//+9/zwxmh2GsvYuA9Hb2txnK5FDeDkyZM7fX5mtv921n93mvfTOO5FjWb0htUojklRQ9JOb1ww2Kn5gC7EwT6upEUtRNyEHSfgceV5ZpoWbLvttvmptdHNa3TnG93kxonBTjvt1HF1L67kxXSiuVWcPMWJVdRINHdfG22Eo5YkHkAVXe2ut956+YQnutqNqvu4UhZfxnFjY/wd448v3bgpu1Ub5LiBMh7cFSdK0VY/Ph8nu9EsIJqANd5g2ldxIhI31Dbf1F6Le0Dips24KTe67+yPByFGl8hxEhwnkNEVZt3VbqzfuMpYi2Zt0Zwu7vGJ+YtOBaJ2Jq7ANt9A2ltRJiHWaYw/lifWc33y00o074mAFqKGKK7aRplGKIryiRPrmd3G+jJf3Ykrs9F9bHStGttrzH9069t4tTau5kaAit/rr79+DiLRtezMrLN4+nZ0yxvlG2UWV5IjaMb8xMlhfz0NPcJynOjGfhj7WrNYjljmODZEU6C4KBDbcFzNjuZVsV4au0uObozjpDr2hSinOLmO2pp4Pbq3jvVTr4uYZowj7seK/Tb231iP8dn4fzx0Mo4Tse/HdhrDx//r7mijhiC6Co+QFjfYR7iJYaKb3Hh6djQJis/HgytjW491GMs6s/eTxb4Vx49YvujKt76wEeONTiB6El0gR6cJUfMRHQfE33E8jmWMp83H8TCOf43HiNi24rVY3xHy4qQ9yqX52NXOcbGV3q7/7sRnovv0KONY5xFsY96j695GMb7YrqKsYNgY6O62YLA8ZLCV6Pby7W9/e8dDA7/whS90dPPa2J1rV+No7rYxuoLdfPPNczez8WCpeMhYPFys8UFa8QCqeHjVQgstVM0zzzzVdtttV917770tu5GM7mM//elP54em1Q8ri2Eau4D8wx/+0PGwuJ4ephVdiUY3rrGss88+e34wWXcPGWzWVVeXteOPPz5/Nh7615V4kFsME/Ndj7NVl5St5qHu0jXmudGf//zn/ACvKMfonjO6AW1+yGCIB3zFAwtjXcZDzuJBe909aK03y/+tb30rl090r9qbhww2PvgsuiqNLmOju+bf/e53HV3HdteNaG+2se7mq7uuY7vqajfWZXTJHA8ZjAfDxTbZ+JDBEF2NRhel0RVpDPfe9763euqpp1p289rVvHX3kMF4mGI8gHKDDTbo8iGD5557bqfXu+sCuFl0Vxv7Y3OXqY3lFfMb87HOOuvkLnZbdVdcdzUdDyCNY0aUUayzeBhfPDivsZxiv4+yjO22+SGDTz75ZC6npZZaKu+r0a331ltvXf30pz+dYb1Hl9bR/XA9XKyvWG+16MY6ph/bfW8fMtisVdnEfh7rIsYb2+HPfvaz6nOf+1wup96Kbnff8Y535HUU6yoeyhfjiC6CuzrG1A+RjH0+Hh7b6kGc7RwXW22jvVn/XW13Ibo0j201tpco31VXXbU66qij8rbRaM8998wPSIXhZFT8M9ABCAAGs2j+EjUg8WDCqEGjb6L73d52MTvSPfHEE7k25uyzz1bzwbDing8A6EE00/vCF76Qm/ENpl7nBrNo4tgoAkc8myWaG9Gz73//+7lnNMGD4UbNBwDQ76LDh3jAZ9QYxb1LcQ9V3FB92223ddtpAjC8ueEcAOh3ceN3dAgQzYeiM4no9OHoo48WPGCEU/MBAAAU4Z4PAACgCOEDAAAY3Pd8RG8f8cCweEBPPHwNAAAYmaqqSlOnTs0PRe3uIa99Dh8RPJZaaqm+fhwAABhmJk+enJZccsn+Dx9R41FPYPz48X0dDQAAMMRNmTIlV0zUGaHfw0fd1CqCh/ABAACM6uF2DDecAwAARQgfAABAEcIHAABQhPABAAAUIXwAAABFCB8AAEARwgcAAFCE8AEAABQhfAAAAEUIHwAAQBHCBwAAUITwAQAAFCF8AAAARQgfAABAEcIHAABQhPABAAAUIXwAAABFCB8AAEARwgcAAFCE8AEAABQhfAAAAEUIHwAAQBHCBwAAUITwAQAAFCF8AAAARQgfAABAEcIHAABQhPABAAAUIXwAAABFCB8AAEARwgcAAFCE8AEAABQhfAAAAEUIHwAAQBHCBwAAUMSwCB+TJk1KBx10UP4NAAAMTsMifDz00EPpjjvuyL8BAIDBaViEDwAAYPATPgAAgCKEDwAAoAjhAwAAKEL4AAAAihA+AACAIoQPAACgCOEDAAAoQvgAAACKED4AAIAihA8AAKAI4QMAAChC+AAAAIoQPgAAgCKEDwAAoAjhAwAAKEL4AAAAihA+AACAIoQPAACgCOEDAAAoQvgAAACKED4AAIAihA8AAKAI4QMAAChC+AAAAIoQPgAAgCKEDwAAoAjhAwAAKEL4AAAAihA+AACAIoQPAACgCOEDAAAoQvgAAACKED4AAIAihA8AAKAI4QMAAChC+AAAAIoQPgAAgCKEDwAAoAjhAwAAKEL4AAAAihA+AACAIoQPAACgCOEDAAAoQvgAAACKED4AAIAihA8AAKAI4QMAAChC+AAAAIoQPgAAgCKEDwAAoAjhAwAAKEL4AAAAihA+AACAIoQPAACgCOEDAAAoQvgAAACKED4AAIAihA8AAKAI4QMAAChC+AAAAIoQPgAAgCKEDwAAoAjhAwAAKEL4AAAAihA+AACAIoQPAACgCOEDAAAoQvgAAACKED4AAIAihA8AAKAI4QMAAChC+AAAAIoQPgAAgCKGRfh4+eWXO/0GAAAGn2ERPh544IFOvwEAgMFnWIQPAABg8BM+AACAIoQPAACgCOEDAAAoQvgAAACKED4AAIAihA8AAKAI4QMAAChC+AAAAIoQPgAAgCKEDwAAoAjhAwAAKEL4AAAAihA+AACAIoQPAACgCOEDAAAoQvgAAACKED4AAIAihA8AAKAI4QMAAChC+AAAAIoQPgAAgCKEDwAAoAjhAwAAKEL4AAAAihA+AACAIoQPAACgCOEDAAAoQvgAAACKED4AAIAihA8AAKAI4QMAAChC+AAAAIoQPgAAgCKEDwAAoAjhAwAAKEL4AAAAihA+AACAIoQPAACgCOEDAAAoQvgAAACKED4AAIAihA8AAKAI4QMAAChC+AAAAIoQPgAAgCKEDwAAoAjhAwAAKEL4AAAAihA+AACAIoQPAACgCOEDAAAoQvgAAACKED4AAIAihA8AAKAI4QMAAChC+AAAAIoQPgAAgCKEDwAAoAjhAwAAKEL4AAAAihA+AACAIoQPAACgCOEDAAAoQvgAAACKED4AAIAihA8AAKAI4QMAAChC+AAAAIoQPgAAgCKEDwAAoIhRVVVVffnglClT0oQJE9ILL7yQxo8fnwbKlltuOcvGPXbs2DR69Oj06quvpsbVFK/XP7PPPnsaN25cmmOOOdK8886b3njjjTTPPPOkSZMm5XU011xzpQUWWCA988wz6fXXX08LLbRQWmKJJdITTzyRxznnnHOm5ZZbLi255JJp2WWXTbfffnu66aab0n//+988zhVXXDG/HtNZY4010oMPPpjuuuuuPN5tttkmTZs2LZ133nl5WquuumraZJNN8v+fffbZPI7rr78+vfLKK3keVl555TzOiRMnpuWXXz49//zz+We++ebL87Xmmmvm5bvzzjvz5+Mz8dpss83W47qK+ejqc/V7Tz/99AzTax6m/vxb3vKWvJztzkc7ZtU0e7Mu2plGXz7Tn/Pc358tsTyDcdpD3UhfdyN9+YHBZ9ogOy71NhsM6fAxK4PHSBShIERAqC222GJp//33T5tvvnmXn7vmmmvSj3/84xyomj8Xmt/rzTCx88RO1c58tKPVPPfHNNtdFz1No7vxzcp10dtptPvZEsvTX/PK/xnp626kLz8w+FwzCI9Lwz58CB4zitqRqHlpx/rrr59Pum+88caO1z75yU+mXXfdNT300EPpzDPPzLUn3/jGN7o8mTz88MPTRhttlD74wQ/mWpzGz8Xmtcoqq6R//etfaYMNNkibbbZZ+utf/5qnF6/fd999adSoUR2ff+yxx9JRRx2V5p9//hyCvvKVr6TFF1+8x/loR/M899c0e7MuNt5445bvtZpGT+ObFeuinWm0+9kSyzMrlnOkG+nrbqQvPzD4XDNIj0vDOnyMhOARQSKab7300ku5uVZjWLjlllvy/yM0RJOvqVOn5iZgUQ7R1Kq29tpr52Zc0XQsPhfNuWpxwh81HVGOF154Ydptt93y6+uss0565JFH0hlnnJHHP3369PS1r30tb9T1a7WoJYiNPppwHXnkkXk6tQhB73znO/P/YzorrLBCxzD1OB944IGOWpaLL744v1eP75vf/GY67LDDOqYb89vVfLSjeZ5j8++PafZ2XcRyRtnWulq/3Y2vuzKZmXXRzjTa/WyJ5ZkVyznSjfR1N9KXHxh8pg3i41Jvs0Gvbzh/7bXX8kgbf+h/UWj1CevHP/7xTsEjNP4dIWyHHXboKJ/G4BHqMoqNcamllur0Xpx0v+Md78gb8amnnpo/Hz8bbrhhevzxx3MbwlAHgsbXavF3VPfF+40bf/jnP//ZMc4nn3yy0zD1OOP1epgYvnF8Y8aM6TTd7uajHc3z3F/T7O26iP836moa3Y1vVq2LdqbR7mdLLM+sWM6RbqSvu5G+/MDgc+cwOC71Onwcc8wx+cS4/mk+maV/xI3ktahOaxZpshbNlqJ5UFcaA2Kc+DaLG8/Df/7zn47XogYlxM1LtajOa36t8e/6/VbvNY+jq79j+ObxNU+3q/loR1fjmtlp9nZdtBpPq2l0N7525quv89zTNNr9bInl6cpATnuoG+nrbqQvPzD4PDsMjku9Dh9f/vKX84lv/TN58uRZO2cjVPRMVYt2e13VjIS4XyLuV+hKY5VXHSoaRTIO0dNWc0iJXhNqUX3X/Frj3/X7rd5rHkdXf8fwzeNrnm5X89GOrsY1s9Ps7bpoNZ5W0+hufO3MV1/nuadptPvZEsvTlYGc9lA30tfdSF9+YPBZYBgcl3odPup7Chp/6H91zUbcF3DaaaflrnEbNf591VVXpUsuuaSjfBZeeOFOw9ZlFNVwzWEx7me4/PLLc3vAuMG87jo4bgSPGpG6291oshU3MDW+Vou/o2eFeD+GaxTdAtfjXHTRRTsNU48zXq+HieEbx/fmm292mm5389GO5nnur2n2dl3E/xt1NY3uxjer1kU702j3syWWZ1Ys50g30tfdSF9+YPBZcxgcl4bkQwbjpHu4i3s+nnvuuRnu+ahvNg9xv0bcbF7XWDR2kRviZvN6Y2y82by+5yPGHzeYx43W9T0JN9xwQ9ppp53y/+OZF3HjUtTA7LfffjPcuBR/R5du8X4MF8O//PLL+Xf0whDzHuOJG85jmKg9u+iii/Lv6667Lr8e78dwMfy9996b9t577/zeHnvskT8T973E693NRzua57m/ptnbdRH/b3yvq2l0N75ZtS7amUa7ny2xPLNiOUe6kb7uRvryA4PPbMPguDQke7saSb1eDfRzPiI9x0bc7nM+6s9195yP7oZpfuZGb+ajv5/z0ZdptrsueppGd+Obleuit9No97Mllqe/5pX/M9LX3UhffmDwuWYQHpeGdVe7jTzh3BPO+8oTzvtnGp5wPjKM9HU30pcfGHymDbLj0ogJH+GEE07Iz6p417velQ455JABnRcAABhppvT3cz4AAABmhvABAAAUIXwAAABFCB8AAEARwgcAAFCE8AEAABQhfAAAAEUIHwAAQBHCBwAAUITwAQAAFCF8AAAARQgfAABAEcIHAABQhPABAAAUIXwAAABFCB8AAEARwgcAAFCE8AEAABQhfAAAAEUIHwAAQBHCBwAAUITwAQAAFCF8AAAARQgfAABAEcIHAABQhPABAAAUIXwAAABFCB8AAEARwgcAAFCE8AEAABQhfAAAAEUIHwAAQBHCBwAAUITwAQAAFCF8AAAARQgfAABAEcIHAABQhPABAAAUIXwAAABFCB8AAEARwgcAAFCE8AEAABQhfAAAAEUIHwAAQBHCBwAAUITwAQAAFCF8AAAARQgfAABAEcIHAABQhPABAAAUIXwAAABFCB8AAEARwgcAAFCE8AEAABQhfAAAAEUIHwAAQBHCBwAAUITwAQAAFCF8AAAARQgfAABAEcIHAABQhPABAAAUIXwAAABFCB8AAEARwgcAAFCE8AEAABQhfAAAAEUIHwAAQBHCBwAAUITwAQAAFCF8AAAARQyL8LHCCit0+g0AAAw+wyJ8jBs3rtNvAABg8BkW4QMAABj8hA8AAKAI4QMAAChC+AAAAIoQPgAAgCKEDwAAoAjhAwAAKEL4AAAAihA+AACAIoQPAACgCOEDAAAoQvgAAACKED4AAIAihA8AAKAI4QMAAChC+AAAAIoQPgAAgCKEDwAAoAjhAwAAKEL4AAAAihA+AACAIoQPAACgCOEDAAAoQvgAAACKED4AAIAihA8AAKAI4QMAAChC+AAAAIoQPgAAgCKEDwAAoAjhAwAAKEL4AAAAihA+AACAIoQPAACgCOEDAAAoQvgAAACKED4AAIAihA8AAKAI4QMAAChC+AAAAIoQPgAAgCKEDwAAoAjhAwAAKEL4AAAAihA+AACAIoQPAACgCOEDAAAoQvgAAACKED4AAIAihA8AAKAI4QMAAChC+AAAAIoQPgAAgCKEDwAAoAjhAwAAKEL4AAAAihA+AACAIoQPAACgCOEDAAAoQvgAAACKED4AAIAihA8AAKAI4QMAAChC+AAAAIoQPgAAgCKEDwAAoAjhAwAAKEL4AAAAihA+AACAIoQPAACgCOEDAAAoQvgAAACKED4AAIAihA8AAKCIYRE+lltuubTWWmvl3wAAwOA0qqqqqi8fnDJlSpowYUJ64YUX0vjx4/t/zgAAgCGht9lgWNR8AAAAg5/wAQAAFCF8AAAARQgfAABAEcIHAABQhPABAAAUIXwAAABFCB8AAEARwgcAAFCE8AEAABQhfAAAAEUIHwAAQBHCBwAAUITwAQAAFCF8AAAARQgfAABAEcIHAABQhPABAAAUIXwAAABFCB8AAEARwgcAAFCE8AEAABQhfAAAAEUIHwAAQBHCBwAAUITwAQAAFCF8AAAARQgfAABAEcIHAABQhPABAAAUIXwAAABFCB8AAEARwgcAAFCE8AEAABQhfAAAAEUIHwAAQBFj+vrBqqry7ylTpvTn/AAAAENMnQnqjNDv4WPq1Kn591JLLdXXUQAAAMNIZIQJEyZ0+f6oqqd40oXp06enxx57LM0777xp1KhRaaCTVoSgyZMnp/Hjxw/ovDDzlOfwo0yHF+U5vCjP4UeZDi9Thkh5RqSI4LH44oun0aNH93/NR4x0ySWXTINJFMhgLhTaozyHH2U6vCjP4UV5Dj/KdHgZPwTKs7saj5obzgEAgCKEDwAAoIhhET7Gjh2bDj/88PyboU95Dj/KdHhRnsOL8hx+lOnwMnaYlWefbzgHAAAYcTUfAADA4Cd8AAAARQgfAABAEcIHAABQxLAIHz/60Y/Ssssum+acc8604YYbpptuummgZ4kWrrnmmrTzzjvnJ1+OGjUqXXDBBZ3ej74PDjvssDRx4sQ011xzpW222Sbdf//9nYZ59tln0wc/+MH8kJ355psv7b333unFF18svCSEY445Jr3tbW9L8847b1pkkUXSu9/97nTfffd1GubVV19NBxxwQFpwwQXTPPPMk3bffff05JNPdhrm3//+d9ppp53SuHHj8ngOPfTQ9OabbxZeGk4++eS05pprdjzEaqONNkqXXHJJx/vKcmg79thj83H34IMP7nhNmQ4tRxxxRC7Dxp9VV121433lOfQ8+uij6UMf+lAuszjveetb35puueWWYX9eNOTDxznnnJMOOeSQ3AXZrbfemtZaa6203XbbpaeeemqgZ40mL730Ui6fCIutfOc730k/+MEP0imnnJJuvPHGNPfcc+eyjANqLXawu+66K11++eXp4osvzoFmn332KbgU1K6++ur8RXfDDTfk8njjjTfStttum8u59tnPfjZddNFF6dxzz83DP/bYY2m33XbreH/atGn5i/D1119P1113XfrlL3+ZTj/99Hywpawll1wyn6D+/e9/z19+W221Vdpll13y/haU5dB18803p5/85Cc5XDZSpkPPW97ylvT44493/Pztb3/reE95Di3PPfdc2mSTTdLss8+eL/Tcfffd6fjjj0/zzz//8D8vqoa4DTbYoDrggAM6/p42bVq1+OKLV8ccc8yAzhfdi03v/PPP7/h7+vTp1WKLLVYdd9xxHa89//zz1dixY6uzzjor/3333Xfnz918880dw1xyySXVqFGjqkcffbTwEtDsqaeeyuVz9dVXd5Tf7LPPXp177rkdw9xzzz15mOuvvz7//cc//rEaPXp09cQTT3QMc/LJJ1fjx4+vXnvttQFYChrNP//81c9+9jNlOYRNnTq1WmmllarLL7+82mKLLaqDDjoov65Mh57DDz+8WmuttVq+pzyHni9+8YvVpptu2uX7w/m8aEjXfER6j6t0UQ1VGz16dP77+uuvH9B5oz0PPfRQeuKJJzqV5YQJE3Izuros43dUKa6//vodw8TwUeZxRYCB9cILL+TfCyywQP4d+2bUhjSWaTQRWHrppTuVaVQzL7rooh3DxFWdKVOmdFxxp7y4Qnr22WfnWqxofqUsh66onYyr3Y1lF5Tp0BRNbqLp8vLLL5+veEczqqA8h54LL7wwn8/sscceuQncOuusk0499dQRcV40pMPH008/nb8kG3ekEH9HgTF01OXVXVnG79hBG40ZMyaf7CrvgTV9+vTcljyqkNdYY438WpTJHHPMkQ+M3ZVpqzKv36Osf/zjH7mteDxFd999903nn39+Wn311ZXlEBUBMpojx/1ZzZTp0BMnndFM6k9/+lO+RytOTjfbbLM0depU5TkEPfjgg7kcV1pppXTppZem/fbbLx144IG5OdxwPy8aM9AzAAyPq6v//Oc/O7U/ZuhZZZVV0u23355rsX73u9+lvfbaK7cdZ+iZPHlyOuigg3I78OiMhaFvhx126Ph/3L8TYWSZZZZJv/3tb/PNyAy9i3brr79+Ovroo/PfUfMR36Nxf0cce4ezIV3zsdBCC6XZZpttht4c4u/FFltswOaL9tXl1V1Zxu/mjgSil47o6UF5D5xPf/rT+Sa3K6+8Mt+0XIsyiaaRzz//fLdl2qrM6/coK66crrjiimm99dbLV8ujg4gTTzxRWQ5B0QwnjpfrrrtuvhIaPxEk4+bV+H9cPVWmQ1vUcqy88spp0qRJ9tEhaOLEiblmudFqq63W0ZRuOJ8XjR7qX5TxJXnFFVd0SpLxd7RTZuhYbrnl8o7SWJbRDjXaLNZlGb/jwBpfqrW//OUvuczjChBlRb8BETyiaU6UQ5Rho9g3oxePxjKNrnjjwNpYptHUp/HgGVdqo8vA5oMy5cW+9dprrynLIWjrrbfO5RE1WfVPXGWN+wTq/yvToS26U33ggQfySax9dOjZZJNNZuie/l//+leuzRr250XVEHf22WfnO/9PP/30fNf/PvvsU80333ydenNg8PS6ctttt+Wf2PROOOGE/P9HHnkkv3/sscfmsvvDH/5Q3XnnndUuu+xSLbfcctUrr7zSMY7tt9++Wmeddaobb7yx+tvf/pZ7cXn/+98/gEs1cu23337VhAkTqquuuqp6/PHHO35efvnljmH23Xffaumll67+8pe/VLfccku10UYb5Z/am2++Wa2xxhrVtttuW91+++3Vn/70p2rhhReuvvzlLw/QUo1cX/rSl3JPZQ899FDe/+Lv6DHlsssuy+8ry6GvsberoEyHls997nP5eBv76LXXXltts8021UILLZR7GgzKc2i56aabqjFjxlRHHXVUdf/991dnnnlmNW7cuOqMM87oGGa4nhcN+fARTjrppLzDzTHHHLnr3RtuuGGgZ4kWrrzyyhw6mn/22muvjm7lvv71r1eLLrpoDpRbb711dd9993UaxzPPPJN3qnnmmSd3D/ixj30shxrKa1WW8fOLX/yiY5g4QO6///65y9Y4qO666645oDR6+OGHqx122KGaa6658hdpfMG+8cYbA7BEI9vHP/7xaplllsnH0Tghif2vDh5BWQ6/8KFMh5Y999yzmjhxYt5Hl1hiifz3pEmTOt5XnkPPRRddlANhnPOsuuqq1U9/+tNO7w/X86JR8c9A174AAADD35C+5wMAABg6hA8AAKAI4QMAAChC+AAAAIoQPgAAgCKEDwAAoAjhAwAAKEL4AAAAihA+ABjyll122fT973+/22FGjRqVLrjggmLzBMCMhA+AQer6669Ps802W9ppp53SULLlllumgw8+uNfDP/zwwzkY1D8LLrhg2nbbbdNtt93W63HcfPPNaZ999unjHANQivABMEj9/Oc/T5/5zGfSNddckx577LE03P35z39Ojz/+eLr00kvTiy++mHbYYYf0/PPP9+qzCy+8cBo3btwsn0cAZo7wATAIxcn3Oeeck/bbb79c83H66ad3vHfVVVflGoI4SV9nnXXSXHPNlbbaaqv01FNPpUsuuSStttpqafz48ekDH/hAevnllzs+99prr6UDDzwwLbLIImnOOedMm266aa4xqMU05ptvvk7zEc2UYlq1I444Iq299trp17/+dW7qNGHChPS+970vTZ06Nb//0Y9+NF199dXpxBNP7KjJiJqN3ogaj8UWWyytv/766bvf/W568skn04033pgeeOCBtMsuu6RFF100zTPPPOltb3tbDirdNbu6//770+abb56Xc/XVV0+XX355W+sfgFlD+AAYhH7729+mVVddNa2yyirpQx/6UDrttNNSVVWdhokg8MMf/jBdd911afLkyem9731vPgH/zW9+k/73f/83XXbZZemkk07qGP4LX/hC+v3vf59++ctfpltvvTWtuOKKabvttkvPPvtsW/MWYSBCycUXX5x/Imwce+yx+b0IHRtttFH65Cc/mWsx4meppZZqe/kjUIXXX389B7Edd9wxXXHFFbkp1vbbb5923nnn9O9//7vlZ6dPn5522223NMccc+Twcsopp6QvfvGLbc8DAP1P+AAYpE2uInSEONl+4YUX8kl+oyOPPDJtsskmufZj7733zu+ffPLJ+e/NNtssvec970lXXnllHvall17K7x133HG5OVPUBpx66qn5JD+m1Y44uY9akjXWWCNP58Mf/nAOBiFqQuKkP5pARS1G/MR9K+2Iplbf+ta3ci3HBhtskNZaa630qU99Kk9vpZVWyu+tsMIK6cILL2z5+agVuffee9OvfvWr/NmoATn66KPbmgcAZg3hA2CQue+++9JNN92U3v/+9+e/x4wZk/bcc88ZQsKaa67Z8f9okhQn/Msvv3yn16IpVl1b8cYbb+SwUpt99tnzyf0999zT1vxFE6d555234++JEyd2TGdmbLzxxjlwzD///OmOO+7Izc5iGaLm4/Of/3xuThbNwmKYmOeuaj7ivahtWXzxxTtei9oYAAbemIGeAQA6i5Dx5ptvdjp5jiZXY8eOzc2sGsNDLe6taPy7fi1qKXpr9OjRMzTtisDSbGan05UIG1EjE/d+NN57EsEj7tmI+0CiqVjU1kStTjTJAmBoUfMBMIhE6IjmQscff3y6/fbbO36iJiDCyFlnndWn8UYzpWgOde2113YKFnHDeZzw1z1GxY3j0USrFtNuV0xn2rRpbX8uaitiPptveo95jhvZd9111/TWt741N+Xq7ib2qCGJe2DifpPaDTfc0Pb8AND/1HwADCJxA/dzzz2X7+GI+yca7b777rlWJO7baNfcc8+de8469NBD0wILLJCWXnrp9J3vfCf3hhXTChtuuGFuuvWVr3wl94oVN2s39rLVTrOs+GwEhGgiFdOLWpW+ivs8zjvvvHyTedSyfP3rX++2pmWbbbZJK6+8ctprr73yupoyZUr66le/2ufpA9B/1HwADCIRLuLkuTl41OHjlltuSXfeeWefxh09UsU44gbxddddN02aNCl31xv3WIQICWeccUb64x//mGsYopYletRqVzSTipvMo0YlalO6ujejt0444YQ8j3FPSASQ6KEr5r8rEXTOP//89Morr+R7Wj7xiU+ko446aqbmAYD+MapqbuALAAAwC6j5AAAAihA+AJil9t1333zvR6ufeA+AkUOzKwBmqXgGSNz03cr48ePTIossUnyeABgYwgcAAFCEZlcAAEARwgcAAFCE8AEAABQhfAAAAEUIHwAAQBHCBwAAUITwAQAApBL+HxlmC4gnG5vyAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load preprocessed data\n",
        "df = pd.read_csv(\"IBM_AML_Preprocessed.csv\")\n",
        "\n",
        "# 🔹 Convert columns to correct data types\n",
        "df[\"Timestamp\"] = pd.to_datetime(df[\"Timestamp\"], errors='coerce')  # Convert to datetime\n",
        "df[\"Amount_Paid\"] = pd.to_numeric(df[\"Amount_Paid\"], errors='coerce')  # Convert to float\n",
        "df[\"Amount_Received\"] = pd.to_numeric(df[\"Amount_Received\"], errors='coerce')  # Convert to float\n",
        "\n",
        "# 1️⃣ Detect Rapid Transaction Bursts (Velocity Analysis)\n",
        "df[\"Time_Diff\"] = df.groupby(\"Sender_Account\")[\"Timestamp\"].diff().dt.total_seconds()\n",
        "df[\"Is_Burst\"] = df[\"Time_Diff\"].apply(lambda x: 1 if pd.notna(x) and x < 60 else 0)  # Transactions < 1 min apart\n",
        "\n",
        "# 2️⃣ Unusual Amounts (Amount Deviation)\n",
        "df[\"Z_Score_Amount\"] = (df[\"Amount_Paid\"] - df[\"Amount_Paid\"].mean()) / df[\"Amount_Paid\"].std()\n",
        "df[\"Is_Anomalous_Amount\"] = df[\"Z_Score_Amount\"].apply(lambda x: 1 if abs(x) > 3 else 0)  # Flag outliers beyond 3 std\n",
        "\n",
        "# 3️⃣ Detect Circular Transactions (Same sender & receiver)\n",
        "df[\"Is_Circular\"] = df.apply(lambda x: 1 if x[\"Sender_Account\"] == x[\"Receiver_Account\"] else 0, axis=1)\n",
        "\n",
        "# 4️⃣ Currency Arbitrage (Different currencies)\n",
        "df[\"Currency_Arbitrage\"] = df.apply(lambda x: 1 if x[\"Receiving_Currency\"] != x[\"Payment_Currency\"] else 0, axis=1)\n",
        "\n",
        "# Visualize anomalies\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.boxplot(x=df[\"Amount_Paid\"])\n",
        "plt.title(\"Transaction Amount Distribution (Detecting Outliers)\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROPZEsmnq0SK",
        "outputId": "1e897677-2388-4c54-d7f7-10bcb4698df6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Behavioral analysis completed! Flags added.\n"
          ]
        }
      ],
      "source": [
        "# Save flagged transactions\n",
        "df.to_csv(\"Behavioral_Analysis_Results.csv\", index=False)\n",
        "print(\"Behavioral analysis completed! Flags added.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhzSDaeExhTD",
        "outputId": "f288256c-0394-43b4-a6e9-37588222d358"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting python-louvain\n",
            "  Downloading python-louvain-0.16.tar.gz (204 kB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Requirement already satisfied: networkx in c:\\users\\keeer\\appdata\\roaming\\python\\python313\\site-packages (from python-louvain) (3.4.2)\n",
            "Requirement already satisfied: numpy in c:\\users\\keeer\\appdata\\roaming\\python\\python313\\site-packages (from python-louvain) (2.2.4)\n",
            "Building wheels for collected packages: python-louvain\n",
            "  Building wheel for python-louvain (pyproject.toml): started\n",
            "  Building wheel for python-louvain (pyproject.toml): finished with status 'done'\n",
            "  Created wheel for python-louvain: filename=python_louvain-0.16-py3-none-any.whl size=9473 sha256=4f8e45030323c659897802e85f1a2ff741eb1406b100c2fc2f9cdf9dc06f647c\n",
            "  Stored in directory: c:\\users\\keeer\\appdata\\local\\pip\\cache\\wheels\\ee\\52\\54\\7ecd0f1ebf5f5a8466f70a27ed2b94d20b955376879d6159c5\n",
            "Successfully built python-louvain\n",
            "Installing collected packages: python-louvain\n",
            "Successfully installed python-louvain-0.16\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "pip install python-louvain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kMpJO3RxhX_",
        "outputId": "29c0b07a-f2cf-4d3c-ccef-d62b5f8b86a4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Detecting Cycles: 100%|██████████| 1264/1264 [00:00<00:00, 146505.66it/s]\n"
          ]
        }
      ],
      "source": [
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from community import community_louvain\n",
        "from tqdm import tqdm  # Progress bar for large computations\n",
        "\n",
        "# Load dataset (ensure it is preprocessed correctly)\n",
        "df = pd.read_csv(\"IBM_AML_Preprocessed.csv\")\n",
        "\n",
        "# Create a directed graph for transaction flow\n",
        "G = nx.from_pandas_edgelist(df, source=\"Sender_Account\", target=\"Receiver_Account\", edge_attr=\"Amount_Paid\", create_using=nx.DiGraph())\n",
        "\n",
        "## **1️⃣ Approximate Degree Centrality (Faster)**\n",
        "degree_centrality = dict(G.in_degree())  # Only in-degree (receiving transactions)\n",
        "df[\"Degree_Centrality\"] = df[\"Sender_Account\"].map(degree_centrality)\n",
        "\n",
        "## **2️⃣ Approximate PageRank (Faster Computation)**\n",
        "pagerank_scores = nx.pagerank(G, alpha=0.85, max_iter=50)  # Limits iterations to 50 for speed\n",
        "df[\"PageRank_Score\"] = df[\"Sender_Account\"].map(pagerank_scores)\n",
        "\n",
        "## **3️⃣ Community Detection with Sampling (Louvain)**\n",
        "# Instead of processing the entire graph, we process a **reduced subgraph** of active accounts\n",
        "subgraph_nodes = set(df[\"Sender_Account\"].sample(n=min(5000, len(df)), random_state=42))  # Sample 5000 nodes\n",
        "G_sub = G.subgraph(subgraph_nodes)\n",
        "\n",
        "partition = community_louvain.best_partition(G_sub.to_undirected())\n",
        "df[\"Community_ID\"] = df[\"Sender_Account\"].map(partition).fillna(-1)  # Assign -1 to accounts not in the sample\n",
        "\n",
        "## **4️⃣ Efficient Cycle Detection (Only for Suspicious Accounts)**\n",
        "# Instead of detecting cycles for the whole graph, we check only high-risk nodes (based on PageRank score)\n",
        "high_risk_accounts = df[df[\"PageRank_Score\"] > df[\"PageRank_Score\"].quantile(0.95)][\"Sender_Account\"].unique()\n",
        "cycles_detected = set()\n",
        "\n",
        "for account in tqdm(high_risk_accounts, desc=\"Detecting Cycles\"):\n",
        "    if account in G:\n",
        "        try:\n",
        "            cycles = list(nx.find_cycle(G, source=account, orientation=\"original\"))  # Faster than `simple_cycles`\n",
        "            if len(cycles) > 0:\n",
        "                cycles_detected.add(account)\n",
        "        except nx.NetworkXNoCycle:\n",
        "            continue  # No cycle found\n",
        "\n",
        "df[\"Is_Cyclic_Transaction\"] = df[\"Sender_Account\"].apply(lambda x: 1 if x in cycles_detected else 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAnfGAkYq0b1",
        "outputId": "1abd4eb3-565e-41dc-f004-fa9506aadb7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Optimized Graph Analysis Completed!\n"
          ]
        }
      ],
      "source": [
        "# Save graph-based features\n",
        "df.to_csv(\"Graph_Analysis_Optimized.csv\", index=False)\n",
        "\n",
        "print(\"✅ Optimized Graph Analysis Completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtYZK1Q9q0fO",
        "outputId": "07d9283d-7a4e-48f1-cfcf-8476a1b7918c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting torch\n",
            "  Downloading torch-2.6.0-cp313-cp313-win_amd64.whl.metadata (28 kB)\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.21.0-cp313-cp313-win_amd64.whl.metadata (6.3 kB)\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "Requirement already satisfied: networkx in c:\\users\\keeer\\appdata\\roaming\\python\\python313\\site-packages (3.4.2)\n",
            "Requirement already satisfied: pandas in c:\\users\\keeer\\appdata\\roaming\\python\\python313\\site-packages (2.2.3)\n",
            "Collecting filelock (from torch)\n",
            "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\keeer\\appdata\\roaming\\python\\python313\\site-packages (from torch) (4.13.0)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\keeer\\appdata\\roaming\\python\\python313\\site-packages (from torch) (3.1.6)\n",
            "Collecting fsspec (from torch)\n",
            "  Downloading fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: setuptools in c:\\users\\keeer\\appdata\\roaming\\python\\python313\\site-packages (from torch) (78.1.0)\n",
            "Collecting sympy==1.13.1 (from torch)\n",
            "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: numpy in c:\\users\\keeer\\appdata\\roaming\\python\\python313\\site-packages (from torchvision) (2.2.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\keeer\\appdata\\roaming\\python\\python313\\site-packages (from torchvision) (11.2.0)\n",
            "Collecting aiohttp (from torch-geometric)\n",
            "  Downloading aiohttp-3.11.15-cp313-cp313-win_amd64.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\keeer\\appdata\\roaming\\python\\python313\\site-packages (from torch-geometric) (7.0.0)\n",
            "Requirement already satisfied: pyparsing in c:\\users\\keeer\\appdata\\roaming\\python\\python313\\site-packages (from torch-geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in c:\\users\\keeer\\appdata\\roaming\\python\\python313\\site-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in c:\\users\\keeer\\appdata\\roaming\\python\\python313\\site-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\keeer\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\keeer\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\keeer\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\keeer\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->torch-geometric)\n",
            "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.1.2 (from aiohttp->torch-geometric)\n",
            "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\keeer\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp->torch-geometric)\n",
            "  Downloading frozenlist-1.5.0-cp313-cp313-win_amd64.whl.metadata (14 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->torch-geometric)\n",
            "  Downloading multidict-6.3.0-cp313-cp313-win_amd64.whl.metadata (5.3 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp->torch-geometric)\n",
            "  Downloading propcache-0.3.1-cp313-cp313-win_amd64.whl.metadata (11 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp->torch-geometric)\n",
            "  Downloading yarl-1.18.3-cp313-cp313-win_amd64.whl.metadata (71 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\keeer\\appdata\\roaming\\python\\python313\\site-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\keeer\\appdata\\roaming\\python\\python313\\site-packages (from requests->torch-geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\keeer\\appdata\\roaming\\python\\python313\\site-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\keeer\\appdata\\roaming\\python\\python313\\site-packages (from requests->torch-geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\keeer\\appdata\\roaming\\python\\python313\\site-packages (from requests->torch-geometric) (2025.1.31)\n",
            "Requirement already satisfied: colorama in c:\\users\\keeer\\appdata\\roaming\\python\\python313\\site-packages (from tqdm->torch-geometric) (0.4.6)\n",
            "Downloading torch-2.6.0-cp313-cp313-win_amd64.whl (204.1 MB)\n",
            "   ---------------------------------------- 0.0/204.1 MB ? eta -:--:--\n",
            "    --------------------------------------- 2.9/204.1 MB 15.7 MB/s eta 0:00:13\n",
            "   - -------------------------------------- 7.1/204.1 MB 18.9 MB/s eta 0:00:11\n",
            "   -- ------------------------------------- 11.5/204.1 MB 19.4 MB/s eta 0:00:10\n",
            "   --- ------------------------------------ 16.3/204.1 MB 20.4 MB/s eta 0:00:10\n",
            "   ---- ----------------------------------- 22.8/204.1 MB 22.7 MB/s eta 0:00:08\n",
            "   ----- ---------------------------------- 30.1/204.1 MB 25.0 MB/s eta 0:00:07\n",
            "   ------- -------------------------------- 37.0/204.1 MB 26.1 MB/s eta 0:00:07\n",
            "   -------- ------------------------------- 44.0/204.1 MB 27.2 MB/s eta 0:00:06\n",
            "   ---------- ----------------------------- 52.2/204.1 MB 28.4 MB/s eta 0:00:06\n",
            "   ------------ --------------------------- 61.3/204.1 MB 30.2 MB/s eta 0:00:05\n",
            "   ------------- -------------------------- 68.9/204.1 MB 30.7 MB/s eta 0:00:05\n",
            "   --------------- ------------------------ 77.6/204.1 MB 31.4 MB/s eta 0:00:05\n",
            "   ---------------- ----------------------- 86.5/204.1 MB 32.2 MB/s eta 0:00:04\n",
            "   ------------------ --------------------- 95.4/204.1 MB 33.0 MB/s eta 0:00:04\n",
            "   ------------------- ------------------- 103.5/204.1 MB 33.5 MB/s eta 0:00:04\n",
            "   --------------------- ----------------- 111.4/204.1 MB 33.7 MB/s eta 0:00:03\n",
            "   ---------------------- ---------------- 119.5/204.1 MB 33.9 MB/s eta 0:00:03\n",
            "   ------------------------ -------------- 126.4/204.1 MB 33.8 MB/s eta 0:00:03\n",
            "   ------------------------- ------------- 134.5/204.1 MB 34.1 MB/s eta 0:00:03\n",
            "   --------------------------- ----------- 143.4/204.1 MB 34.5 MB/s eta 0:00:02\n",
            "   ---------------------------- ---------- 151.3/204.1 MB 34.6 MB/s eta 0:00:02\n",
            "   ------------------------------ -------- 159.6/204.1 MB 34.9 MB/s eta 0:00:02\n",
            "   -------------------------------- ------ 167.8/204.1 MB 35.2 MB/s eta 0:00:02\n",
            "   --------------------------------- ----- 176.2/204.1 MB 35.4 MB/s eta 0:00:01\n",
            "   ----------------------------------- --- 186.1/204.1 MB 35.8 MB/s eta 0:00:01\n",
            "   ------------------------------------- - 194.5/204.1 MB 36.0 MB/s eta 0:00:01\n",
            "   --------------------------------------  203.9/204.1 MB 36.3 MB/s eta 0:00:01\n",
            "   --------------------------------------  203.9/204.1 MB 36.3 MB/s eta 0:00:01\n",
            "   --------------------------------------- 204.1/204.1 MB 34.6 MB/s eta 0:00:00\n",
            "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
            "   ----------------------------------- ---- 5.5/6.2 MB 26.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 6.2/6.2 MB 23.1 MB/s eta 0:00:00\n",
            "Downloading torchvision-0.21.0-cp313-cp313-win_amd64.whl (1.6 MB)\n",
            "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
            "   ---------------------------------------- 1.6/1.6 MB 22.0 MB/s eta 0:00:00\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 1.1/1.1 MB 31.8 MB/s eta 0:00:00\n",
            "Downloading aiohttp-3.11.15-cp313-cp313-win_amd64.whl (436 kB)\n",
            "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Downloading fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
            "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading frozenlist-1.5.0-cp313-cp313-win_amd64.whl (51 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
            "   --------------------------------------- 536.2/536.2 kB 29.0 MB/s eta 0:00:00\n",
            "Downloading multidict-6.3.0-cp313-cp313-win_amd64.whl (37 kB)\n",
            "Downloading propcache-0.3.1-cp313-cp313-win_amd64.whl (44 kB)\n",
            "Downloading yarl-1.18.3-cp313-cp313-win_amd64.whl (315 kB)\n",
            "Installing collected packages: mpmath, sympy, propcache, multidict, fsspec, frozenlist, filelock, aiohappyeyeballs, yarl, torch, aiosignal, torchvision, aiohttp, torch-geometric\n",
            "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.11.15 aiosignal-1.3.2 filelock-3.18.0 frozenlist-1.5.0 fsspec-2025.3.2 mpmath-1.3.0 multidict-6.3.0 propcache-0.3.1 sympy-1.13.1 torch-2.6.0 torch-geometric-2.6.1 torchvision-0.21.0 yarl-1.18.3\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "pip install torch torchvision torch-geometric networkx pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeqdsuqD9FYK",
        "outputId": "94ecab3e-3307-4628-c35f-a10eae3b6cd8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\298465671.py:28: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:257.)\n",
            "  node_feature_matrix = torch.tensor(list(node_features.values()), dtype=torch.float)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Loss: 25.131481170654297\n",
            "Epoch 10, Loss: 7.011607646942139\n",
            "Epoch 20, Loss: 2.7564640045166016\n",
            "Epoch 30, Loss: 2.023149251937866\n",
            "Epoch 40, Loss: 1.7845275402069092\n",
            "Epoch 50, Loss: 0.693501353263855\n",
            "Epoch 60, Loss: 0.8479993939399719\n",
            "Epoch 70, Loss: 1.1934115886688232\n",
            "Epoch 80, Loss: 0.9727692008018494\n",
            "Epoch 90, Loss: 1.0842887163162231\n",
            "Epoch 100, Loss: 0.9889825582504272\n",
            "Epoch 110, Loss: 1.1629835367202759\n",
            "Epoch 120, Loss: 0.9458729028701782\n",
            "Epoch 130, Loss: 1.0906466245651245\n",
            "Epoch 140, Loss: 0.9933303594589233\n",
            "Epoch 150, Loss: 1.138321042060852\n",
            "Epoch 160, Loss: 0.934059739112854\n",
            "Epoch 170, Loss: 1.0786429643630981\n",
            "Epoch 180, Loss: 0.9803715348243713\n",
            "Epoch 190, Loss: 1.1186147928237915\n",
            "Accuracy: 50.09%\n"
          ]
        }
      ],
      "source": [
        "#GNN Graph analysis\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "\n",
        "# Load preprocessed data\n",
        "df = pd.read_csv(\"IBM_AML_Preprocessed.csv\")\n",
        "\n",
        "# 1️⃣ Create the Directed Graph for Transaction Network\n",
        "G = nx.from_pandas_edgelist(df, source=\"Sender_Account\", target=\"Receiver_Account\", edge_attr=\"Amount_Paid\", create_using=nx.DiGraph())\n",
        "\n",
        "# 2️⃣ Map Accounts to Numeric Indices (for GNN compatibility)\n",
        "account_mapping = {account: idx for idx, account in enumerate(G.nodes())}\n",
        "df[\"Sender_Account_Index\"] = df[\"Sender_Account\"].map(account_mapping)\n",
        "df[\"Receiver_Account_Index\"] = df[\"Receiver_Account\"].map(account_mapping)\n",
        "\n",
        "# 3️⃣ Define Node Features (e.g., Account-based features)\n",
        "node_features = {}\n",
        "for node in G.nodes():\n",
        "    node_features[node] = np.array([G.degree(node), np.mean([G[u][v]['Amount_Paid'] for u, v in G.edges(node)]) if len(list(G.edges(node))) > 0 else 0])  # Avoid empty edge list for mean\n",
        "\n",
        "# Convert the node features to a torch tensor\n",
        "node_feature_matrix = torch.tensor(list(node_features.values()), dtype=torch.float)\n",
        "\n",
        "# 4️⃣ Build Edge Index (for PyG)\n",
        "# Ensure numeric indices for edge index\n",
        "edge_index = torch.tensor([(account_mapping[src], account_mapping[tgt]) for src, tgt in G.edges()], dtype=torch.long).t().contiguous()\n",
        "\n",
        "# 5️⃣ Define Labels (1 for fraud, 0 for normal)\n",
        "# For simplicity, we set labels randomly. In your case, labels would come from your dataset.\n",
        "labels = torch.randint(0, 2, (len(G.nodes()),), dtype=torch.long)\n",
        "\n",
        "# 6️⃣ Create PyTorch Geometric Data Object\n",
        "data = Data(x=node_feature_matrix, edge_index=edge_index, y=labels)\n",
        "\n",
        "# 7️⃣ Build the Graph Convolutional Network (GCN) Model\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, 16)  # First layer\n",
        "        self.conv2 = GCNConv(16, out_channels)  # Output layer (binary classification)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "# 8️⃣ Initialize the GNN Model\n",
        "model = GCN(in_channels=2, out_channels=2)  # 2 features for each node, output 2 classes (fraud or not)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 9️⃣ Train the GNN Model\n",
        "def train(model, data, optimizer, criterion, epochs=100):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data)\n",
        "        loss = criterion(out, data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
        "\n",
        "train(model, data, optimizer, criterion, epochs=200)\n",
        "\n",
        "# 🔟 Evaluate the Model (Test set can be split in a real-world case)\n",
        "model.eval()\n",
        "out = model(data)\n",
        "pred = out.argmax(dim=1)\n",
        "accuracy = (pred == data.y).sum().item() / len(data.y)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HE_s8ziH9FmZ",
        "outputId": "9342a74d-3b3b-4eb1-9094-e9b7f6e8b28d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Loss: 10.474234580993652\n",
            "Epoch 10, Loss: 1.5377274751663208\n",
            "Epoch 20, Loss: 1.5812432765960693\n",
            "Epoch 30, Loss: 1.0678766965866089\n",
            "Epoch 40, Loss: 0.7380349636077881\n",
            "Epoch 50, Loss: 0.718515932559967\n",
            "Epoch 60, Loss: 0.6948429942131042\n",
            "Epoch 70, Loss: 0.7064915895462036\n",
            "Epoch 80, Loss: 0.7104066014289856\n",
            "Epoch 90, Loss: 0.7130109071731567\n",
            "Epoch 100, Loss: 0.7198626399040222\n",
            "Epoch 110, Loss: 0.7216996550559998\n",
            "Epoch 120, Loss: 0.7195293307304382\n",
            "Epoch 130, Loss: 0.72109454870224\n",
            "Epoch 140, Loss: 0.7218303084373474\n",
            "Epoch 150, Loss: 0.7213998436927795\n",
            "Epoch 160, Loss: 0.7219792008399963\n",
            "Epoch 170, Loss: 0.7220170497894287\n",
            "Epoch 180, Loss: 0.7220139503479004\n",
            "Epoch 190, Loss: 0.7221583127975464\n",
            "GNN Node Embeddings Saved Successfully!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "\n",
        "# Load preprocessed data\n",
        "df = pd.read_csv(\"IBM_AML_Preprocessed.csv\")\n",
        "\n",
        "# 1️⃣ Create the Directed Graph for Transaction Network\n",
        "G = nx.from_pandas_edgelist(df, source=\"Sender_Account\", target=\"Receiver_Account\", edge_attr=\"Amount_Paid\", create_using=nx.DiGraph())\n",
        "\n",
        "# 2️⃣ Map Accounts to Numeric Indices (for GNN compatibility)\n",
        "account_mapping = {account: idx for idx, account in enumerate(G.nodes())}\n",
        "df[\"Sender_Account_Index\"] = df[\"Sender_Account\"].map(account_mapping)\n",
        "df[\"Receiver_Account_Index\"] = df[\"Receiver_Account\"].map(account_mapping)\n",
        "\n",
        "# 3️⃣ Define Node Features\n",
        "node_features = {node: np.array([G.degree(node),\n",
        "                                 np.mean([G[u][v]['Amount_Paid'] for u, v in G.edges(node)])\n",
        "                                 if len(list(G.edges(node))) > 0 else 0]) for node in G.nodes()}\n",
        "\n",
        "# Convert the node features to a torch tensor\n",
        "node_feature_matrix = torch.tensor(list(node_features.values()), dtype=torch.float)\n",
        "\n",
        "# 4️⃣ Build Edge Index\n",
        "edge_index = torch.tensor([(account_mapping[src], account_mapping[tgt]) for src, tgt in G.edges()], dtype=torch.long).t().contiguous()\n",
        "\n",
        "# 5️⃣ Define Labels (Random for now, replace with actual fraud labels)\n",
        "labels = torch.randint(0, 2, (len(G.nodes()),), dtype=torch.long)\n",
        "\n",
        "# 6️⃣ Create PyTorch Geometric Data Object\n",
        "data = Data(x=node_feature_matrix, edge_index=edge_index, y=labels)\n",
        "\n",
        "# 7️⃣ Build the GCN Model\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, 16)\n",
        "        self.conv2 = GCNConv(16, out_channels)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "# 8️⃣ Initialize the GNN Model\n",
        "model = GCN(in_channels=2, out_channels=2)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 9️⃣ Train the GNN Model\n",
        "def train(model, data, optimizer, criterion, epochs=100):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data)\n",
        "        loss = criterion(out, data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
        "\n",
        "train(model, data, optimizer, criterion, epochs=200)\n",
        "\n",
        "# 🔟 Extract Node Embeddings from the Trained Model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    node_embeddings = model.conv1(data.x, data.edge_index).numpy()\n",
        "\n",
        "# Convert embeddings to DataFrame with correct number of columns\n",
        "embedding_df = pd.DataFrame(node_embeddings, columns=[f\"GNN_Embedding_{i+1}\" for i in range(node_embeddings.shape[1])])\n",
        "\n",
        "# Add account mapping\n",
        "embedding_df[\"Sender_Account\"] = list(account_mapping.keys())\n",
        "\n",
        "# Save embeddings\n",
        "embedding_df.to_csv(\"GNN_Node_Embeddings.csv\", index=False)\n",
        "print(\"GNN Node Embeddings Saved Successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4rcCxIh9dX6",
        "outputId": "23425c9c-4ee8-49cd-f9d2-66e7c512228c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\2399626798.py:4: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  behavioral_df = pd.read_csv(\"Behavioral_Analysis_Results.csv\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully Merged Behavioral & GNN Features!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load behavioral and graph-based data\n",
        "behavioral_df = pd.read_csv(\"Behavioral_Analysis_Results.csv\")\n",
        "gnn_embeddings_df = pd.read_csv(\"GNN_Node_Embeddings.csv\")\n",
        "\n",
        "# Merge on Sender_Account (ensuring we match embeddings with accounts)\n",
        "merged_df = pd.merge(behavioral_df, gnn_embeddings_df, on=\"Sender_Account\", how=\"left\")\n",
        "\n",
        "# Save merged dataset\n",
        "merged_df.to_csv(\"Merged_Behavioral_GNN_Features.csv\", index=False)\n",
        "\n",
        "print(\"Successfully Merged Behavioral & GNN Features!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrWhl9e_9da-",
        "outputId": "c95367de-cb16-462a-bbce-78574facbedc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\259249215.py:11: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(\"Merged_Behavioral_GNN_Features.csv\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔹 Model: Random Forest\n",
            "Accuracy: 0.9997\n",
            "Precision: 0.9492\n",
            "Recall: 0.4553\n",
            "F1 Score: 0.6154\n",
            "AUC-ROC: 0.8786\n",
            "\n",
            "🔹 Model: XGBoost\n",
            "Accuracy: 0.9997\n",
            "Precision: 0.9365\n",
            "Recall: 0.4797\n",
            "F1 Score: 0.6344\n",
            "AUC-ROC: 0.9824\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\keeer\\AppData\\Roaming\\Python\\Python313\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
            "[WinError 2] The system cannot find the file specified\n",
            "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
            "  warnings.warn(\n",
            "  File \"C:\\Users\\keeer\\AppData\\Roaming\\Python\\Python313\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
            "    cpu_info = subprocess.run(\n",
            "        \"wmic CPU Get NumberOfCores /Format:csv\".split(),\n",
            "        capture_output=True,\n",
            "        text=True,\n",
            "    )\n",
            "  File \"c:\\Python313\\Lib\\subprocess.py\", line 556, in run\n",
            "    with Popen(*popenargs, **kwargs) as process:\n",
            "         ~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Python313\\Lib\\subprocess.py\", line 1038, in __init__\n",
            "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
            "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "                        pass_fds, cwd, env,\n",
            "                        ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "                        gid, gids, uid, umask,\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^\n",
            "                        start_new_session, process_group)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Python313\\Lib\\subprocess.py\", line 1550, in _execute_child\n",
            "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
            "                       ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
            "                             # no special security\n",
            "                             ^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<4 lines>...\n",
            "                             cwd,\n",
            "                             ^^^^\n",
            "                             startupinfo)\n",
            "                             ^^^^^^^^^^^^\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 492, number of negative: 838368\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.076657 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 8113\n",
            "[LightGBM] [Info] Number of data points in the train set: 838860, number of used features: 45\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000587 -> initscore=-7.440734\n",
            "[LightGBM] [Info] Start training from score -7.440734\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\keeer\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "C:\\Users\\keeer\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔹 Model: LightGBM\n",
            "Accuracy: 0.9986\n",
            "Precision: 0.2007\n",
            "Recall: 0.4390\n",
            "F1 Score: 0.2755\n",
            "AUC-ROC: 0.8423\n",
            "\n",
            " Fraud Detection Modeling Completed & Results Saved!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# 1️⃣ Load the merged dataset (Behavior + Graph + GNN Features)\n",
        "df = pd.read_csv(\"Merged_Behavioral_GNN_Features.csv\")\n",
        "\n",
        "# 2️⃣ Handle Missing Values\n",
        "df.fillna(0, inplace=True)\n",
        "\n",
        "# 3️⃣ Encode Categorical Variables (if any)\n",
        "if df.select_dtypes(include=['object']).shape[1] > 0:\n",
        "    label_encoders = {}\n",
        "    for col in df.select_dtypes(include=['object']).columns:\n",
        "        df[col] = df[col].astype(str)  # Convert all categorical values to strings\n",
        "        le = LabelEncoder()\n",
        "        df[col] = le.fit_transform(df[col])\n",
        "        label_encoders[col] = le  # Store for inverse transform if needed\n",
        "\n",
        "# 4️⃣ Define Features (X) and Target (y)\n",
        "target_col = \"Is_Laundering\"  # Corrected target column name\n",
        "X = df.drop(columns=[target_col])  # Assuming \"Is_Laundering\" is the target column\n",
        "y = df[target_col]\n",
        "\n",
        "# 5️⃣ Split Data into Training and Test Sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# 6️⃣ Scale Features (Standardization)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# 7️⃣ Train Models\n",
        "models = {\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    \"XGBoost\": XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42),\n",
        "    \"LightGBM\": lgb.LGBMClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "}\n",
        "\n",
        "# 8️⃣ Evaluate Models\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_prob = model.predict_proba(X_test)[:, 1]  # Probability scores for ROC-AUC\n",
        "\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall\": recall_score(y_test, y_pred),\n",
        "        \"F1 Score\": f1_score(y_test, y_pred),\n",
        "        \"AUC-ROC\": roc_auc_score(y_test, y_prob)\n",
        "    }\n",
        "\n",
        "    results[name] = metrics\n",
        "    print(f\"\\n🔹 Model: {name}\")\n",
        "    for metric, value in metrics.items():\n",
        "        print(f\"{metric}: {value:.4f}\")\n",
        "\n",
        "# Convert results to DataFrame and save\n",
        "results_df = pd.DataFrame(results).T\n",
        "results_df.to_csv(\"Fraud_Detection_Model_Results.csv\", index=True)\n",
        "\n",
        "print(\"\\n Fraud Detection Modeling Completed & Results Saved!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kicBuu2JR6j-",
        "outputId": "8b2ee28b-155a-4ed8-db33-f25dbc90028f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting imbalanced-learn\n",
            "  Downloading imbalanced_learn-0.13.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.24.3 in c:\\users\\keeer\\appdata\\roaming\\python\\python313\\site-packages (from imbalanced-learn) (2.2.4)\n",
            "Requirement already satisfied: scipy<2,>=1.10.1 in c:\\users\\keeer\\appdata\\roaming\\python\\python313\\site-packages (from imbalanced-learn) (1.15.2)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.3.2 in c:\\users\\keeer\\appdata\\roaming\\python\\python313\\site-packages (from imbalanced-learn) (1.6.1)\n",
            "Collecting sklearn-compat<1,>=0.1 (from imbalanced-learn)\n",
            "  Downloading sklearn_compat-0.1.3-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: joblib<2,>=1.1.1 in c:\\users\\keeer\\appdata\\roaming\\python\\python313\\site-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\keeer\\appdata\\roaming\\python\\python313\\site-packages (from imbalanced-learn) (3.6.0)\n",
            "Downloading imbalanced_learn-0.13.0-py3-none-any.whl (238 kB)\n",
            "Downloading sklearn_compat-0.1.3-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: sklearn-compat, imbalanced-learn\n",
            "Successfully installed imbalanced-learn-0.13.0 sklearn-compat-0.1.3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install imbalanced-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tn2EK_a9gOjV",
        "outputId": "3b920b13-b6a9-4b34-c7b8-e5e0e24da732"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-04-01 12:53:34,574] A new study created in memory with name: no-name-4b7954a5-d04f-41b1-b135-9eaffd68d54b\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"gamma\": trial.suggest_uniform(\"gamma\", 0, 5),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.0001, 1),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.0001, 1),\n",
            "[I 2025-04-01 12:53:41,916] Trial 0 finished with value: 0.24201680672268908 and parameters: {'n_estimators': 222, 'max_depth': 5, 'learning_rate': 0.21010704177717146, 'subsample': 0.9908477148648469, 'colsample_bytree': 0.5567419563425318, 'gamma': 2.7514005268962523, 'reg_alpha': 0.00018934609001969733, 'reg_lambda': 0.003191357070375552}. Best is trial 0 with value: 0.24201680672268908.\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"gamma\": trial.suggest_uniform(\"gamma\", 0, 5),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.0001, 1),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.0001, 1),\n",
            "[I 2025-04-01 12:53:47,003] Trial 1 finished with value: 0.011488200660571537 and parameters: {'n_estimators': 161, 'max_depth': 3, 'learning_rate': 0.024031627248592622, 'subsample': 0.735879590953033, 'colsample_bytree': 0.6801649951962894, 'gamma': 2.8552225619451104, 'reg_alpha': 0.7798234044774481, 'reg_lambda': 0.0006754555489499565}. Best is trial 0 with value: 0.24201680672268908.\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"gamma\": trial.suggest_uniform(\"gamma\", 0, 5),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.0001, 1),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.0001, 1),\n",
            "[I 2025-04-01 12:54:10,313] Trial 2 finished with value: 0.018621337661228324 and parameters: {'n_estimators': 474, 'max_depth': 5, 'learning_rate': 0.013530000708424202, 'subsample': 0.6812080007129311, 'colsample_bytree': 0.6995756119065206, 'gamma': 1.9028722718624596, 'reg_alpha': 0.06593769374440048, 'reg_lambda': 0.6328652029366407}. Best is trial 0 with value: 0.24201680672268908.\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"gamma\": trial.suggest_uniform(\"gamma\", 0, 5),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.0001, 1),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.0001, 1),\n",
            "[I 2025-04-01 12:54:27,428] Trial 3 finished with value: 0.020773775490756624 and parameters: {'n_estimators': 340, 'max_depth': 6, 'learning_rate': 0.015038084098022868, 'subsample': 0.7160624362863528, 'colsample_bytree': 0.9996254609172427, 'gamma': 2.791869329517419, 'reg_alpha': 0.008606039266830096, 'reg_lambda': 0.00030973392353249735}. Best is trial 0 with value: 0.24201680672268908.\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"gamma\": trial.suggest_uniform(\"gamma\", 0, 5),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.0001, 1),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.0001, 1),\n",
            "[I 2025-04-01 12:54:49,941] Trial 4 finished with value: 0.01876172607879925 and parameters: {'n_estimators': 490, 'max_depth': 4, 'learning_rate': 0.019728425566863446, 'subsample': 0.6078045711277795, 'colsample_bytree': 0.661213076103915, 'gamma': 0.01735376203595873, 'reg_alpha': 0.000358286336824627, 'reg_lambda': 0.00048106241438722693}. Best is trial 0 with value: 0.24201680672268908.\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"gamma\": trial.suggest_uniform(\"gamma\", 0, 5),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.0001, 1),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.0001, 1),\n",
            "[I 2025-04-01 12:55:08,488] Trial 5 finished with value: 0.6288659793814433 and parameters: {'n_estimators': 324, 'max_depth': 10, 'learning_rate': 0.19387765268250548, 'subsample': 0.8345728259658918, 'colsample_bytree': 0.6618585841999445, 'gamma': 0.20765753509663754, 'reg_alpha': 0.0018479598945925987, 'reg_lambda': 0.018840743619798827}. Best is trial 5 with value: 0.6288659793814433.\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"gamma\": trial.suggest_uniform(\"gamma\", 0, 5),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.0001, 1),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.0001, 1),\n",
            "[I 2025-04-01 12:55:30,559] Trial 6 finished with value: 0.029080118694362018 and parameters: {'n_estimators': 469, 'max_depth': 5, 'learning_rate': 0.027305056322326243, 'subsample': 0.9511559541471788, 'colsample_bytree': 0.7344819024283137, 'gamma': 4.880194935344805, 'reg_alpha': 0.11388128264408506, 'reg_lambda': 0.0008921931709337844}. Best is trial 5 with value: 0.6288659793814433.\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"gamma\": trial.suggest_uniform(\"gamma\", 0, 5),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.0001, 1),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.0001, 1),\n",
            "[I 2025-04-01 12:55:41,430] Trial 7 finished with value: 0.011018777833891925 and parameters: {'n_estimators': 251, 'max_depth': 3, 'learning_rate': 0.014136805721544365, 'subsample': 0.858443099602388, 'colsample_bytree': 0.7817448178251059, 'gamma': 1.433325454364458, 'reg_alpha': 0.015494405561442747, 'reg_lambda': 0.013424788806961343}. Best is trial 5 with value: 0.6288659793814433.\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"gamma\": trial.suggest_uniform(\"gamma\", 0, 5),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.0001, 1),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.0001, 1),\n",
            "[I 2025-04-01 12:56:15,916] Trial 8 finished with value: 0.2222222222222222 and parameters: {'n_estimators': 495, 'max_depth': 10, 'learning_rate': 0.0189638250706449, 'subsample': 0.6463421022802913, 'colsample_bytree': 0.9376605561834248, 'gamma': 0.7578222895660153, 'reg_alpha': 0.016322711018405336, 'reg_lambda': 0.0035935662774245133}. Best is trial 5 with value: 0.6288659793814433.\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"gamma\": trial.suggest_uniform(\"gamma\", 0, 5),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.0001, 1),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.0001, 1),\n",
            "[I 2025-04-01 12:56:39,666] Trial 9 finished with value: 0.07329842931937172 and parameters: {'n_estimators': 373, 'max_depth': 8, 'learning_rate': 0.02247836436842688, 'subsample': 0.8471679935075718, 'colsample_bytree': 0.547135353234409, 'gamma': 4.7110293402694134, 'reg_alpha': 0.00015311569122827525, 'reg_lambda': 0.00041643593397405743}. Best is trial 5 with value: 0.6288659793814433.\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"gamma\": trial.suggest_uniform(\"gamma\", 0, 5),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.0001, 1),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.0001, 1),\n",
            "[I 2025-04-01 12:56:49,459] Trial 10 finished with value: 0.5084745762711864 and parameters: {'n_estimators': 114, 'max_depth': 10, 'learning_rate': 0.2226981035829722, 'subsample': 0.5147209205756024, 'colsample_bytree': 0.8341220774648284, 'gamma': 4.0228533198062735, 'reg_alpha': 0.0008587187987569421, 'reg_lambda': 0.05866667194059967}. Best is trial 5 with value: 0.6288659793814433.\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"gamma\": trial.suggest_uniform(\"gamma\", 0, 5),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.0001, 1),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.0001, 1),\n",
            "[I 2025-04-01 12:56:58,894] Trial 11 finished with value: 0.5169491525423728 and parameters: {'n_estimators': 101, 'max_depth': 10, 'learning_rate': 0.23366743168789758, 'subsample': 0.5206843931046354, 'colsample_bytree': 0.8436053444829716, 'gamma': 3.8639032907690516, 'reg_alpha': 0.0017563439556487585, 'reg_lambda': 0.07538114719489504}. Best is trial 5 with value: 0.6288659793814433.\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"gamma\": trial.suggest_uniform(\"gamma\", 0, 5),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.0001, 1),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.0001, 1),\n",
            "[I 2025-04-01 12:57:17,756] Trial 12 finished with value: 0.5855855855855856 and parameters: {'n_estimators': 292, 'max_depth': 8, 'learning_rate': 0.10340997931538705, 'subsample': 0.8383570346061973, 'colsample_bytree': 0.8594053593154865, 'gamma': 3.4364595708409564, 'reg_alpha': 0.0024327919777124567, 'reg_lambda': 0.12253958300941013}. Best is trial 5 with value: 0.6288659793814433.\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"gamma\": trial.suggest_uniform(\"gamma\", 0, 5),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.0001, 1),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.0001, 1),\n",
            "[I 2025-04-01 12:57:36,556] Trial 13 finished with value: 0.5777777777777777 and parameters: {'n_estimators': 288, 'max_depth': 8, 'learning_rate': 0.09796239856553081, 'subsample': 0.8140887532359554, 'colsample_bytree': 0.6127542889934678, 'gamma': 3.5520511312088865, 'reg_alpha': 0.00230310818663745, 'reg_lambda': 0.3622472502379558}. Best is trial 5 with value: 0.6288659793814433.\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"gamma\": trial.suggest_uniform(\"gamma\", 0, 5),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.0001, 1),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.0001, 1),\n",
            "[I 2025-04-01 12:57:58,792] Trial 14 finished with value: 0.631578947368421 and parameters: {'n_estimators': 395, 'max_depth': 8, 'learning_rate': 0.09979622150469078, 'subsample': 0.9062492795845566, 'colsample_bytree': 0.8835457362362973, 'gamma': 1.8831992932236143, 'reg_alpha': 0.0048100934163496575, 'reg_lambda': 0.06099758758814359}. Best is trial 14 with value: 0.631578947368421.\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"gamma\": trial.suggest_uniform(\"gamma\", 0, 5),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.0001, 1),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.0001, 1),\n",
            "[I 2025-04-01 12:58:25,540] Trial 15 finished with value: 0.6395939086294417 and parameters: {'n_estimators': 412, 'max_depth': 9, 'learning_rate': 0.10661345024799285, 'subsample': 0.9109293870198465, 'colsample_bytree': 0.9232853252026656, 'gamma': 0.10741795414173705, 'reg_alpha': 0.006364170958036962, 'reg_lambda': 0.019315604315307683}. Best is trial 15 with value: 0.6395939086294417.\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"gamma\": trial.suggest_uniform(\"gamma\", 0, 5),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.0001, 1),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.0001, 1),\n",
            "[I 2025-04-01 12:58:49,975] Trial 16 finished with value: 0.2808988764044944 and parameters: {'n_estimators': 410, 'max_depth': 7, 'learning_rate': 0.0489318513714651, 'subsample': 0.928668894813649, 'colsample_bytree': 0.9298165128625763, 'gamma': 1.6137159532297303, 'reg_alpha': 0.0061466397265735285, 'reg_lambda': 0.02801470040338886}. Best is trial 15 with value: 0.6395939086294417.\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"gamma\": trial.suggest_uniform(\"gamma\", 0, 5),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.0001, 1),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.0001, 1),\n",
            "[I 2025-04-01 12:59:28,748] Trial 17 finished with value: 0.6368159203980099 and parameters: {'n_estimators': 415, 'max_depth': 9, 'learning_rate': 0.10566675023496568, 'subsample': 0.9185128849038571, 'colsample_bytree': 0.9078060463562926, 'gamma': 0.7997160878847658, 'reg_alpha': 0.04194858272632979, 'reg_lambda': 0.0036934096917474375}. Best is trial 15 with value: 0.6395939086294417.\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"gamma\": trial.suggest_uniform(\"gamma\", 0, 5),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.0001, 1),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.0001, 1),\n",
            "[I 2025-04-01 13:00:27,843] Trial 18 finished with value: 0.6331658291457286 and parameters: {'n_estimators': 432, 'max_depth': 9, 'learning_rate': 0.058776096203378245, 'subsample': 0.7718649713810917, 'colsample_bytree': 0.987723038954935, 'gamma': 0.8446893684749265, 'reg_alpha': 0.06784627623487334, 'reg_lambda': 0.004099870622307367}. Best is trial 15 with value: 0.6395939086294417.\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"gamma\": trial.suggest_uniform(\"gamma\", 0, 5),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.0001, 1),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.0001, 1),\n",
            "[I 2025-04-01 13:01:10,350] Trial 19 finished with value: 0.6403940886699507 and parameters: {'n_estimators': 440, 'max_depth': 9, 'learning_rate': 0.1411317778092428, 'subsample': 0.9787237041792427, 'colsample_bytree': 0.7967208536284128, 'gamma': 0.779819983721336, 'reg_alpha': 0.25854280710980737, 'reg_lambda': 0.00013595732364460623}. Best is trial 19 with value: 0.6403940886699507.\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"gamma\": trial.suggest_uniform(\"gamma\", 0, 5),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.0001, 1),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.0001, 1),\n",
            "[I 2025-04-01 13:01:50,184] Trial 20 finished with value: 0.31797235023041476 and parameters: {'n_estimators': 366, 'max_depth': 7, 'learning_rate': 0.06276158250628759, 'subsample': 0.9940106957212194, 'colsample_bytree': 0.7706918747871645, 'gamma': 0.5223401642276678, 'reg_alpha': 0.47849859138831136, 'reg_lambda': 0.0001752522040195888}. Best is trial 19 with value: 0.6403940886699507.\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"gamma\": trial.suggest_uniform(\"gamma\", 0, 5),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.0001, 1),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.0001, 1),\n",
            "[I 2025-04-01 13:02:29,786] Trial 21 finished with value: 0.6305418719211823 and parameters: {'n_estimators': 436, 'max_depth': 9, 'learning_rate': 0.14474915092572666, 'subsample': 0.8996442717408063, 'colsample_bytree': 0.9162346007626501, 'gamma': 1.1167621648034696, 'reg_alpha': 0.21521502173452076, 'reg_lambda': 0.001832980448985411}. Best is trial 19 with value: 0.6403940886699507.\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"gamma\": trial.suggest_uniform(\"gamma\", 0, 5),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.0001, 1),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.0001, 1),\n",
            "[I 2025-04-01 13:03:11,123] Trial 22 finished with value: 0.6331658291457286 and parameters: {'n_estimators': 442, 'max_depth': 9, 'learning_rate': 0.12444087967127093, 'subsample': 0.9597332167220313, 'colsample_bytree': 0.8070483920790841, 'gamma': 0.4639841356880756, 'reg_alpha': 0.033916208777329836, 'reg_lambda': 0.00011782731875236536}. Best is trial 19 with value: 0.6403940886699507.\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"gamma\": trial.suggest_uniform(\"gamma\", 0, 5),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.0001, 1),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.0001, 1),\n",
            "[I 2025-04-01 13:03:57,294] Trial 23 finished with value: 0.6176470588235294 and parameters: {'n_estimators': 387, 'max_depth': 9, 'learning_rate': 0.07390610111844201, 'subsample': 0.8986784218329124, 'colsample_bytree': 0.8956612498674252, 'gamma': 1.1636607740235627, 'reg_alpha': 0.2634265039992415, 'reg_lambda': 0.006908734593967679}. Best is trial 19 with value: 0.6403940886699507.\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"gamma\": trial.suggest_uniform(\"gamma\", 0, 5),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.0001, 1),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.0001, 1),\n",
            "[I 2025-04-01 13:04:46,333] Trial 24 finished with value: 0.2608695652173913 and parameters: {'n_estimators': 425, 'max_depth': 7, 'learning_rate': 0.04229507549308917, 'subsample': 0.788750145688094, 'colsample_bytree': 0.9706606287094703, 'gamma': 2.2012643855793863, 'reg_alpha': 0.03153178831199306, 'reg_lambda': 0.0014811189529599826}. Best is trial 19 with value: 0.6403940886699507.\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"gamma\": trial.suggest_uniform(\"gamma\", 0, 5),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.0001, 1),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.0001, 1),\n",
            "[I 2025-04-01 13:05:22,098] Trial 25 finished with value: 0.6530612244897959 and parameters: {'n_estimators': 348, 'max_depth': 9, 'learning_rate': 0.15777882346732924, 'subsample': 0.8765254168318537, 'colsample_bytree': 0.9510349350458817, 'gamma': 0.36075621120175727, 'reg_alpha': 0.16101021333616303, 'reg_lambda': 0.00848738943825752}. Best is trial 25 with value: 0.6530612244897959.\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"gamma\": trial.suggest_uniform(\"gamma\", 0, 5),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.0001, 1),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.0001, 1),\n",
            "[I 2025-04-01 13:06:06,630] Trial 26 finished with value: 0.6262626262626263 and parameters: {'n_estimators': 350, 'max_depth': 8, 'learning_rate': 0.1690171569458183, 'subsample': 0.8741984670575276, 'colsample_bytree': 0.9531287519893741, 'gamma': 0.017149223946109626, 'reg_alpha': 0.952973347696479, 'reg_lambda': 0.16843726496258682}. Best is trial 25 with value: 0.6530612244897959.\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"gamma\": trial.suggest_uniform(\"gamma\", 0, 5),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.0001, 1),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.0001, 1),\n",
            "[I 2025-04-01 13:06:45,658] Trial 27 finished with value: 0.21574344023323616 and parameters: {'n_estimators': 316, 'max_depth': 6, 'learning_rate': 0.0799374563356391, 'subsample': 0.956698964746437, 'colsample_bytree': 0.7322765377963526, 'gamma': 0.37194996621521825, 'reg_alpha': 0.16893852688458852, 'reg_lambda': 0.008424417509038119}. Best is trial 25 with value: 0.6530612244897959.\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"gamma\": trial.suggest_uniform(\"gamma\", 0, 5),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.0001, 1),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.0001, 1),\n",
            "[I 2025-04-01 13:07:06,280] Trial 28 finished with value: 0.5945945945945946 and parameters: {'n_estimators': 261, 'max_depth': 9, 'learning_rate': 0.29375238862676684, 'subsample': 0.9995417524611806, 'colsample_bytree': 0.8739313612289523, 'gamma': 1.1712590888598817, 'reg_alpha': 0.3905930974114071, 'reg_lambda': 0.02673735756006009}. Best is trial 25 with value: 0.6530612244897959.\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"gamma\": trial.suggest_uniform(\"gamma\", 0, 5),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.0001, 1),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.0001, 1),\n",
            "[I 2025-04-01 13:07:36,072] Trial 29 finished with value: 0.6268656716417911 and parameters: {'n_estimators': 210, 'max_depth': 10, 'learning_rate': 0.14423861521468412, 'subsample': 0.9728781082743846, 'colsample_bytree': 0.5094027934776785, 'gamma': 0.6498371932036164, 'reg_alpha': 0.1140099208726533, 'reg_lambda': 0.28573878106507977}. Best is trial 25 with value: 0.6530612244897959.\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"gamma\": trial.suggest_uniform(\"gamma\", 0, 5),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.0001, 1),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.0001, 1),\n",
            "[I 2025-04-01 13:09:04,661] Trial 30 finished with value: 0.18915510718789408 and parameters: {'n_estimators': 461, 'max_depth': 7, 'learning_rate': 0.03457671887335318, 'subsample': 0.799395183270022, 'colsample_bytree': 0.8028944362136791, 'gamma': 1.4939874157121662, 'reg_alpha': 0.021374693757153725, 'reg_lambda': 0.0012484175748010353}. Best is trial 25 with value: 0.6530612244897959.\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"gamma\": trial.suggest_uniform(\"gamma\", 0, 5),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.0001, 1),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.0001, 1),\n",
            "[I 2025-04-01 13:11:35,237] Trial 31 finished with value: 0.6231155778894473 and parameters: {'n_estimators': 401, 'max_depth': 9, 'learning_rate': 0.12246572674704691, 'subsample': 0.9282767029023177, 'colsample_bytree': 0.9076653931163664, 'gamma': 0.8687844748886627, 'reg_alpha': 0.054303134391555825, 'reg_lambda': 0.0028353477121219484}. Best is trial 25 with value: 0.6530612244897959.\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"gamma\": trial.suggest_uniform(\"gamma\", 0, 5),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.0001, 1),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.0001, 1),\n",
            "[I 2025-04-01 13:13:57,981] Trial 32 finished with value: 0.6256410256410256 and parameters: {'n_estimators': 356, 'max_depth': 9, 'learning_rate': 0.16114110823165312, 'subsample': 0.8802604672384582, 'colsample_bytree': 0.9575782710119677, 'gamma': 0.34408975549275767, 'reg_alpha': 0.12575301267910527, 'reg_lambda': 0.03584180953249183}. Best is trial 25 with value: 0.6530612244897959.\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  \"gamma\": trial.suggest_uniform(\"gamma\", 0, 5),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.0001, 1),\n",
            "C:\\Users\\keeer\\AppData\\Local\\Temp\\ipykernel_15020\\3173925449.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.0001, 1),\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def objective(trial):\n",
        "    scale_pos_weight = df[\"Is_Laundering\"].value_counts()[0] / df[\"Is_Laundering\"].value_counts()[1]\n",
        "    params = {\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500),\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
        "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
        "        \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
        "        \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
        "        \"scale_pos_weight\": scale_pos_weight,\n",
        "        \"gamma\": trial.suggest_uniform(\"gamma\", 0, 5),\n",
        "        \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.0001, 1),\n",
        "        \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.0001, 1),\n",
        "    }\n",
        "\n",
        "    model = XGBClassifier(**params, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    return f1_score(y_test, y_pred)\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "print(\"Best parameters:\", study.best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_SWBZXfws7d",
        "outputId": "28bf6c1f-d771-466e-8f1e-bd3d53244cb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters: {'n_estimators': 375, 'max_depth': 10, 'learning_rate': 0.2890454831644262, 'subsample': 0.9571346193817639, 'colsample_bytree': 0.7794782252859026, 'gamma': 3.5127688378663686, 'reg_alpha': 0.0018903585601149047, 'reg_lambda': 0.004260973131397251}\n"
          ]
        }
      ],
      "source": [
        "print(\"Best parameters:\", study.best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "acKcuFqWx8hn",
        "outputId": "b6f39d9a-f463-4af5-a1ab-4879231fb4a8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-87-5675067e789f>:14: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(\"Merged_Behavioral_GNN_Features.csv\")\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [02:22:42] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-logloss:0.30308\n",
            "[1]\tvalidation_0-logloss:0.25301\n",
            "[2]\tvalidation_0-logloss:0.21423\n",
            "[3]\tvalidation_0-logloss:0.17159\n",
            "[4]\tvalidation_0-logloss:0.14158\n",
            "[5]\tvalidation_0-logloss:0.11866\n",
            "[6]\tvalidation_0-logloss:0.10477\n",
            "[7]\tvalidation_0-logloss:0.09146\n",
            "[8]\tvalidation_0-logloss:0.07961\n",
            "[9]\tvalidation_0-logloss:0.07055\n",
            "[10]\tvalidation_0-logloss:0.06413\n",
            "[11]\tvalidation_0-logloss:0.05750\n",
            "[12]\tvalidation_0-logloss:0.05253\n",
            "[13]\tvalidation_0-logloss:0.04969\n",
            "[14]\tvalidation_0-logloss:0.04480\n",
            "[15]\tvalidation_0-logloss:0.04129\n",
            "[16]\tvalidation_0-logloss:0.03752\n",
            "[17]\tvalidation_0-logloss:0.03438\n",
            "[18]\tvalidation_0-logloss:0.03253\n",
            "[19]\tvalidation_0-logloss:0.03003\n",
            "[20]\tvalidation_0-logloss:0.02863\n",
            "[21]\tvalidation_0-logloss:0.02754\n",
            "[22]\tvalidation_0-logloss:0.02588\n",
            "[23]\tvalidation_0-logloss:0.02477\n",
            "[24]\tvalidation_0-logloss:0.02428\n",
            "[25]\tvalidation_0-logloss:0.02317\n",
            "[26]\tvalidation_0-logloss:0.02234\n",
            "[27]\tvalidation_0-logloss:0.02168\n",
            "[28]\tvalidation_0-logloss:0.02105\n",
            "[29]\tvalidation_0-logloss:0.02072\n",
            "[30]\tvalidation_0-logloss:0.01990\n",
            "[31]\tvalidation_0-logloss:0.01939\n",
            "[32]\tvalidation_0-logloss:0.01886\n",
            "[33]\tvalidation_0-logloss:0.01827\n",
            "[34]\tvalidation_0-logloss:0.01774\n",
            "[35]\tvalidation_0-logloss:0.01737\n",
            "[36]\tvalidation_0-logloss:0.01676\n",
            "[37]\tvalidation_0-logloss:0.01654\n",
            "[38]\tvalidation_0-logloss:0.01622\n",
            "[39]\tvalidation_0-logloss:0.01548\n",
            "[40]\tvalidation_0-logloss:0.01484\n",
            "[41]\tvalidation_0-logloss:0.01464\n",
            "[42]\tvalidation_0-logloss:0.01426\n",
            "[43]\tvalidation_0-logloss:0.01385\n",
            "[44]\tvalidation_0-logloss:0.01355\n",
            "[45]\tvalidation_0-logloss:0.01339\n",
            "[46]\tvalidation_0-logloss:0.01320\n",
            "[47]\tvalidation_0-logloss:0.01275\n",
            "[48]\tvalidation_0-logloss:0.01256\n",
            "[49]\tvalidation_0-logloss:0.01207\n",
            "[50]\tvalidation_0-logloss:0.01169\n",
            "[51]\tvalidation_0-logloss:0.01144\n",
            "[52]\tvalidation_0-logloss:0.01113\n",
            "[53]\tvalidation_0-logloss:0.01083\n",
            "[54]\tvalidation_0-logloss:0.01058\n",
            "[55]\tvalidation_0-logloss:0.01049\n",
            "[56]\tvalidation_0-logloss:0.01022\n",
            "[57]\tvalidation_0-logloss:0.01007\n",
            "[58]\tvalidation_0-logloss:0.01000\n",
            "[59]\tvalidation_0-logloss:0.00992\n",
            "[60]\tvalidation_0-logloss:0.00981\n",
            "[61]\tvalidation_0-logloss:0.00971\n",
            "[62]\tvalidation_0-logloss:0.00952\n",
            "[63]\tvalidation_0-logloss:0.00924\n",
            "[64]\tvalidation_0-logloss:0.00906\n",
            "[65]\tvalidation_0-logloss:0.00897\n",
            "[66]\tvalidation_0-logloss:0.00886\n",
            "[67]\tvalidation_0-logloss:0.00873\n",
            "[68]\tvalidation_0-logloss:0.00847\n",
            "[69]\tvalidation_0-logloss:0.00837\n",
            "[70]\tvalidation_0-logloss:0.00829\n",
            "[71]\tvalidation_0-logloss:0.00817\n",
            "[72]\tvalidation_0-logloss:0.00803\n",
            "[73]\tvalidation_0-logloss:0.00790\n",
            "[74]\tvalidation_0-logloss:0.00785\n",
            "[75]\tvalidation_0-logloss:0.00775\n",
            "[76]\tvalidation_0-logloss:0.00766\n",
            "[77]\tvalidation_0-logloss:0.00761\n",
            "[78]\tvalidation_0-logloss:0.00753\n",
            "[79]\tvalidation_0-logloss:0.00741\n",
            "[80]\tvalidation_0-logloss:0.00732\n",
            "[81]\tvalidation_0-logloss:0.00726\n",
            "[82]\tvalidation_0-logloss:0.00721\n",
            "[83]\tvalidation_0-logloss:0.00711\n",
            "[84]\tvalidation_0-logloss:0.00705\n",
            "[85]\tvalidation_0-logloss:0.00700\n",
            "[86]\tvalidation_0-logloss:0.00694\n",
            "[87]\tvalidation_0-logloss:0.00681\n",
            "[88]\tvalidation_0-logloss:0.00679\n",
            "[89]\tvalidation_0-logloss:0.00676\n",
            "[90]\tvalidation_0-logloss:0.00670\n",
            "[91]\tvalidation_0-logloss:0.00665\n",
            "[92]\tvalidation_0-logloss:0.00662\n",
            "[93]\tvalidation_0-logloss:0.00655\n",
            "[94]\tvalidation_0-logloss:0.00652\n",
            "[95]\tvalidation_0-logloss:0.00647\n",
            "[96]\tvalidation_0-logloss:0.00642\n",
            "[97]\tvalidation_0-logloss:0.00632\n",
            "[98]\tvalidation_0-logloss:0.00628\n",
            "[99]\tvalidation_0-logloss:0.00623\n",
            "[100]\tvalidation_0-logloss:0.00620\n",
            "[101]\tvalidation_0-logloss:0.00620\n",
            "[102]\tvalidation_0-logloss:0.00611\n",
            "[103]\tvalidation_0-logloss:0.00605\n",
            "[104]\tvalidation_0-logloss:0.00604\n",
            "[105]\tvalidation_0-logloss:0.00601\n",
            "[106]\tvalidation_0-logloss:0.00597\n",
            "[107]\tvalidation_0-logloss:0.00596\n",
            "[108]\tvalidation_0-logloss:0.00589\n",
            "[109]\tvalidation_0-logloss:0.00586\n",
            "[110]\tvalidation_0-logloss:0.00580\n",
            "[111]\tvalidation_0-logloss:0.00580\n",
            "[112]\tvalidation_0-logloss:0.00580\n",
            "[113]\tvalidation_0-logloss:0.00580\n",
            "[114]\tvalidation_0-logloss:0.00580\n",
            "[115]\tvalidation_0-logloss:0.00580\n",
            "[116]\tvalidation_0-logloss:0.00580\n",
            "[117]\tvalidation_0-logloss:0.00580\n",
            "[118]\tvalidation_0-logloss:0.00580\n",
            "[119]\tvalidation_0-logloss:0.00580\n",
            "[120]\tvalidation_0-logloss:0.00580\n",
            "[121]\tvalidation_0-logloss:0.00574\n",
            "[122]\tvalidation_0-logloss:0.00574\n",
            "[123]\tvalidation_0-logloss:0.00574\n",
            "[124]\tvalidation_0-logloss:0.00574\n",
            "[125]\tvalidation_0-logloss:0.00574\n",
            "[126]\tvalidation_0-logloss:0.00574\n",
            "[127]\tvalidation_0-logloss:0.00574\n",
            "[128]\tvalidation_0-logloss:0.00574\n",
            "[129]\tvalidation_0-logloss:0.00574\n",
            "[130]\tvalidation_0-logloss:0.00574\n",
            "[131]\tvalidation_0-logloss:0.00574\n",
            "[132]\tvalidation_0-logloss:0.00574\n",
            "[133]\tvalidation_0-logloss:0.00574\n",
            "[134]\tvalidation_0-logloss:0.00574\n",
            "[135]\tvalidation_0-logloss:0.00574\n",
            "[136]\tvalidation_0-logloss:0.00574\n",
            "[137]\tvalidation_0-logloss:0.00574\n",
            "[138]\tvalidation_0-logloss:0.00574\n",
            "[139]\tvalidation_0-logloss:0.00574\n",
            "[140]\tvalidation_0-logloss:0.00574\n",
            "[141]\tvalidation_0-logloss:0.00574\n",
            "[142]\tvalidation_0-logloss:0.00574\n",
            "[143]\tvalidation_0-logloss:0.00574\n",
            "[144]\tvalidation_0-logloss:0.00574\n",
            "[145]\tvalidation_0-logloss:0.00574\n",
            "[146]\tvalidation_0-logloss:0.00574\n",
            "[147]\tvalidation_0-logloss:0.00574\n",
            "[148]\tvalidation_0-logloss:0.00574\n",
            "[149]\tvalidation_0-logloss:0.00574\n",
            "[150]\tvalidation_0-logloss:0.00574\n",
            "[151]\tvalidation_0-logloss:0.00574\n",
            "[152]\tvalidation_0-logloss:0.00574\n",
            "[153]\tvalidation_0-logloss:0.00574\n",
            "[154]\tvalidation_0-logloss:0.00574\n",
            "[155]\tvalidation_0-logloss:0.00574\n",
            "[156]\tvalidation_0-logloss:0.00574\n",
            "[157]\tvalidation_0-logloss:0.00574\n",
            "[158]\tvalidation_0-logloss:0.00574\n",
            "[159]\tvalidation_0-logloss:0.00574\n",
            "[160]\tvalidation_0-logloss:0.00574\n",
            "[161]\tvalidation_0-logloss:0.00574\n",
            "[162]\tvalidation_0-logloss:0.00574\n",
            "[163]\tvalidation_0-logloss:0.00574\n",
            "[164]\tvalidation_0-logloss:0.00574\n",
            "[165]\tvalidation_0-logloss:0.00574\n",
            "[166]\tvalidation_0-logloss:0.00574\n",
            "[167]\tvalidation_0-logloss:0.00574\n",
            "[168]\tvalidation_0-logloss:0.00574\n",
            "[169]\tvalidation_0-logloss:0.00574\n",
            "[170]\tvalidation_0-logloss:0.00574\n",
            "[171]\tvalidation_0-logloss:0.00574\n",
            "[172]\tvalidation_0-logloss:0.00574\n",
            "[173]\tvalidation_0-logloss:0.00574\n",
            "[174]\tvalidation_0-logloss:0.00574\n",
            "[175]\tvalidation_0-logloss:0.00574\n",
            "[176]\tvalidation_0-logloss:0.00574\n",
            "[177]\tvalidation_0-logloss:0.00574\n",
            "[178]\tvalidation_0-logloss:0.00574\n",
            "[179]\tvalidation_0-logloss:0.00574\n",
            "[180]\tvalidation_0-logloss:0.00574\n",
            "[181]\tvalidation_0-logloss:0.00574\n",
            "[182]\tvalidation_0-logloss:0.00574\n",
            "[183]\tvalidation_0-logloss:0.00574\n",
            "[184]\tvalidation_0-logloss:0.00572\n",
            "[185]\tvalidation_0-logloss:0.00572\n",
            "[186]\tvalidation_0-logloss:0.00572\n",
            "[187]\tvalidation_0-logloss:0.00572\n",
            "[188]\tvalidation_0-logloss:0.00572\n",
            "[189]\tvalidation_0-logloss:0.00572\n",
            "[190]\tvalidation_0-logloss:0.00572\n",
            "[191]\tvalidation_0-logloss:0.00572\n",
            "[192]\tvalidation_0-logloss:0.00572\n",
            "[193]\tvalidation_0-logloss:0.00572\n",
            "[194]\tvalidation_0-logloss:0.00572\n",
            "[195]\tvalidation_0-logloss:0.00572\n",
            "[196]\tvalidation_0-logloss:0.00572\n",
            "[197]\tvalidation_0-logloss:0.00572\n",
            "[198]\tvalidation_0-logloss:0.00572\n",
            "[199]\tvalidation_0-logloss:0.00572\n",
            "[200]\tvalidation_0-logloss:0.00572\n",
            "[201]\tvalidation_0-logloss:0.00572\n",
            "[202]\tvalidation_0-logloss:0.00572\n",
            "[203]\tvalidation_0-logloss:0.00572\n",
            "[204]\tvalidation_0-logloss:0.00572\n",
            "[205]\tvalidation_0-logloss:0.00572\n",
            "[206]\tvalidation_0-logloss:0.00572\n",
            "[207]\tvalidation_0-logloss:0.00572\n",
            "[208]\tvalidation_0-logloss:0.00572\n",
            "[209]\tvalidation_0-logloss:0.00572\n",
            "[210]\tvalidation_0-logloss:0.00572\n",
            "[211]\tvalidation_0-logloss:0.00572\n",
            "[212]\tvalidation_0-logloss:0.00572\n",
            "[213]\tvalidation_0-logloss:0.00572\n",
            "[214]\tvalidation_0-logloss:0.00572\n",
            "[215]\tvalidation_0-logloss:0.00572\n",
            "[216]\tvalidation_0-logloss:0.00572\n",
            "[217]\tvalidation_0-logloss:0.00572\n",
            "[218]\tvalidation_0-logloss:0.00572\n",
            "[219]\tvalidation_0-logloss:0.00572\n",
            "[220]\tvalidation_0-logloss:0.00572\n",
            "[221]\tvalidation_0-logloss:0.00572\n",
            "[222]\tvalidation_0-logloss:0.00572\n",
            "[223]\tvalidation_0-logloss:0.00572\n",
            "[224]\tvalidation_0-logloss:0.00572\n",
            "[225]\tvalidation_0-logloss:0.00572\n",
            "[226]\tvalidation_0-logloss:0.00572\n",
            "[227]\tvalidation_0-logloss:0.00572\n",
            "[228]\tvalidation_0-logloss:0.00572\n",
            "[229]\tvalidation_0-logloss:0.00572\n",
            "[230]\tvalidation_0-logloss:0.00572\n",
            "[231]\tvalidation_0-logloss:0.00572\n",
            "[232]\tvalidation_0-logloss:0.00572\n",
            "[233]\tvalidation_0-logloss:0.00572\n",
            "[234]\tvalidation_0-logloss:0.00572\n",
            "[235]\tvalidation_0-logloss:0.00572\n",
            "[236]\tvalidation_0-logloss:0.00572\n",
            "[237]\tvalidation_0-logloss:0.00572\n",
            "[238]\tvalidation_0-logloss:0.00572\n",
            "[239]\tvalidation_0-logloss:0.00572\n",
            "[240]\tvalidation_0-logloss:0.00572\n",
            "[241]\tvalidation_0-logloss:0.00572\n",
            "[242]\tvalidation_0-logloss:0.00572\n",
            "[243]\tvalidation_0-logloss:0.00572\n",
            "[244]\tvalidation_0-logloss:0.00572\n",
            "[245]\tvalidation_0-logloss:0.00572\n",
            "[246]\tvalidation_0-logloss:0.00572\n",
            "[247]\tvalidation_0-logloss:0.00572\n",
            "[248]\tvalidation_0-logloss:0.00572\n",
            "[249]\tvalidation_0-logloss:0.00572\n",
            "[250]\tvalidation_0-logloss:0.00572\n",
            "[251]\tvalidation_0-logloss:0.00571\n",
            "[252]\tvalidation_0-logloss:0.00572\n",
            "[253]\tvalidation_0-logloss:0.00572\n",
            "[254]\tvalidation_0-logloss:0.00572\n",
            "[255]\tvalidation_0-logloss:0.00572\n",
            "[256]\tvalidation_0-logloss:0.00572\n",
            "[257]\tvalidation_0-logloss:0.00572\n",
            "[258]\tvalidation_0-logloss:0.00572\n",
            "[259]\tvalidation_0-logloss:0.00572\n",
            "[260]\tvalidation_0-logloss:0.00572\n",
            "[261]\tvalidation_0-logloss:0.00572\n",
            "[262]\tvalidation_0-logloss:0.00572\n",
            "[263]\tvalidation_0-logloss:0.00572\n",
            "[264]\tvalidation_0-logloss:0.00572\n",
            "[265]\tvalidation_0-logloss:0.00572\n",
            "[266]\tvalidation_0-logloss:0.00572\n",
            "[267]\tvalidation_0-logloss:0.00572\n",
            "[268]\tvalidation_0-logloss:0.00572\n",
            "[269]\tvalidation_0-logloss:0.00572\n",
            "[270]\tvalidation_0-logloss:0.00572\n",
            "[271]\tvalidation_0-logloss:0.00572\n",
            "[272]\tvalidation_0-logloss:0.00572\n",
            "[273]\tvalidation_0-logloss:0.00572\n",
            "[274]\tvalidation_0-logloss:0.00572\n",
            "[275]\tvalidation_0-logloss:0.00572\n",
            "[276]\tvalidation_0-logloss:0.00572\n",
            "[277]\tvalidation_0-logloss:0.00572\n",
            "[278]\tvalidation_0-logloss:0.00572\n",
            "[279]\tvalidation_0-logloss:0.00572\n",
            "[280]\tvalidation_0-logloss:0.00572\n",
            "[281]\tvalidation_0-logloss:0.00572\n",
            "[282]\tvalidation_0-logloss:0.00572\n",
            "[283]\tvalidation_0-logloss:0.00572\n",
            "[284]\tvalidation_0-logloss:0.00572\n",
            "[285]\tvalidation_0-logloss:0.00572\n",
            "[286]\tvalidation_0-logloss:0.00572\n",
            "[287]\tvalidation_0-logloss:0.00572\n",
            "[288]\tvalidation_0-logloss:0.00572\n",
            "[289]\tvalidation_0-logloss:0.00572\n",
            "[290]\tvalidation_0-logloss:0.00572\n",
            "[291]\tvalidation_0-logloss:0.00572\n",
            "[292]\tvalidation_0-logloss:0.00572\n",
            "[293]\tvalidation_0-logloss:0.00572\n",
            "[294]\tvalidation_0-logloss:0.00572\n",
            "[295]\tvalidation_0-logloss:0.00572\n",
            "[296]\tvalidation_0-logloss:0.00572\n",
            "[297]\tvalidation_0-logloss:0.00572\n",
            "[298]\tvalidation_0-logloss:0.00572\n",
            "[299]\tvalidation_0-logloss:0.00572\n",
            "[300]\tvalidation_0-logloss:0.00572\n",
            "[301]\tvalidation_0-logloss:0.00572\n",
            "[302]\tvalidation_0-logloss:0.00572\n",
            "[303]\tvalidation_0-logloss:0.00572\n",
            "[304]\tvalidation_0-logloss:0.00572\n",
            "[305]\tvalidation_0-logloss:0.00572\n",
            "[306]\tvalidation_0-logloss:0.00572\n",
            "[307]\tvalidation_0-logloss:0.00572\n",
            "[308]\tvalidation_0-logloss:0.00572\n",
            "[309]\tvalidation_0-logloss:0.00572\n",
            "[310]\tvalidation_0-logloss:0.00572\n",
            "[311]\tvalidation_0-logloss:0.00572\n",
            "[312]\tvalidation_0-logloss:0.00572\n",
            "[313]\tvalidation_0-logloss:0.00572\n",
            "[314]\tvalidation_0-logloss:0.00572\n",
            "[315]\tvalidation_0-logloss:0.00572\n",
            "[316]\tvalidation_0-logloss:0.00572\n",
            "[317]\tvalidation_0-logloss:0.00572\n",
            "[318]\tvalidation_0-logloss:0.00572\n",
            "[319]\tvalidation_0-logloss:0.00572\n",
            "[320]\tvalidation_0-logloss:0.00572\n",
            "[321]\tvalidation_0-logloss:0.00572\n",
            "[322]\tvalidation_0-logloss:0.00572\n",
            "[323]\tvalidation_0-logloss:0.00572\n",
            "[324]\tvalidation_0-logloss:0.00572\n",
            "[325]\tvalidation_0-logloss:0.00572\n",
            "[326]\tvalidation_0-logloss:0.00572\n",
            "[327]\tvalidation_0-logloss:0.00572\n",
            "[328]\tvalidation_0-logloss:0.00572\n",
            "[329]\tvalidation_0-logloss:0.00572\n",
            "[330]\tvalidation_0-logloss:0.00572\n",
            "[331]\tvalidation_0-logloss:0.00572\n",
            "[332]\tvalidation_0-logloss:0.00572\n",
            "[333]\tvalidation_0-logloss:0.00572\n",
            "[334]\tvalidation_0-logloss:0.00572\n",
            "[335]\tvalidation_0-logloss:0.00572\n",
            "[336]\tvalidation_0-logloss:0.00572\n",
            "[337]\tvalidation_0-logloss:0.00572\n",
            "[338]\tvalidation_0-logloss:0.00572\n",
            "[339]\tvalidation_0-logloss:0.00572\n",
            "[340]\tvalidation_0-logloss:0.00572\n",
            "[341]\tvalidation_0-logloss:0.00572\n",
            "[342]\tvalidation_0-logloss:0.00572\n",
            "[343]\tvalidation_0-logloss:0.00572\n",
            "[344]\tvalidation_0-logloss:0.00572\n",
            "[345]\tvalidation_0-logloss:0.00572\n",
            "[346]\tvalidation_0-logloss:0.00572\n",
            "[347]\tvalidation_0-logloss:0.00572\n",
            "[348]\tvalidation_0-logloss:0.00572\n",
            "[349]\tvalidation_0-logloss:0.00572\n",
            "[350]\tvalidation_0-logloss:0.00572\n",
            "[351]\tvalidation_0-logloss:0.00572\n",
            "[352]\tvalidation_0-logloss:0.00572\n",
            "[353]\tvalidation_0-logloss:0.00572\n",
            "[354]\tvalidation_0-logloss:0.00572\n",
            "[355]\tvalidation_0-logloss:0.00572\n",
            "[356]\tvalidation_0-logloss:0.00572\n",
            "[357]\tvalidation_0-logloss:0.00572\n",
            "[358]\tvalidation_0-logloss:0.00572\n",
            "[359]\tvalidation_0-logloss:0.00572\n",
            "[360]\tvalidation_0-logloss:0.00572\n",
            "[361]\tvalidation_0-logloss:0.00572\n",
            "[362]\tvalidation_0-logloss:0.00572\n",
            "[363]\tvalidation_0-logloss:0.00572\n",
            "[364]\tvalidation_0-logloss:0.00572\n",
            "[365]\tvalidation_0-logloss:0.00572\n",
            "[366]\tvalidation_0-logloss:0.00572\n",
            "[367]\tvalidation_0-logloss:0.00572\n",
            "[368]\tvalidation_0-logloss:0.00572\n",
            "[369]\tvalidation_0-logloss:0.00572\n",
            "[370]\tvalidation_0-logloss:0.00572\n",
            "[371]\tvalidation_0-logloss:0.00572\n",
            "[372]\tvalidation_0-logloss:0.00572\n",
            "[373]\tvalidation_0-logloss:0.00572\n",
            "[374]\tvalidation_0-logloss:0.00572\n",
            "Optimal Threshold: 0.6201\n",
            "\n",
            "🔹 Model with Focal Loss (XGBoost)\n",
            "Accuracy: 0.9992\n",
            "Precision: 0.6533\n",
            "Recall: 0.3768\n",
            "F1 Score: 0.4779\n",
            "AUC-ROC: 0.9688\n",
            "\n",
            " Fraud Detection Modeling Completed & Results Saved!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "# 1️⃣ Load the merged dataset (Behavior + Graph + GNN Features)\n",
        "df = pd.read_csv(\"Merged_Behavioral_GNN_Features.csv\")\n",
        "\n",
        "# 2️⃣ Handle Missing Values\n",
        "df.fillna(0, inplace=True)\n",
        "\n",
        "# 3️⃣ Encode Categorical Variables (if any)\n",
        "if df.select_dtypes(include=['object']).shape[1] > 0:\n",
        "    label_encoders = {}\n",
        "    for col in df.select_dtypes(include=['object']).columns:\n",
        "        df[col] = df[col].astype(str)  # Convert all categorical values to strings\n",
        "        le = LabelEncoder()\n",
        "        df[col] = le.fit_transform(df[col])\n",
        "        label_encoders[col] = le  # Store for inverse transform if needed\n",
        "\n",
        "# 4️⃣ Define Features (X) and Target (y)\n",
        "target_col = \"Is_Laundering\"  # Corrected target column name\n",
        "X = df.drop(columns=[target_col])  # Assuming \"Is_Laundering\" is the target column\n",
        "y = df[target_col]\n",
        "\n",
        "# 5️⃣ Split Data into Training and Test Sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "smote = SMOTE(sampling_strategy=0.5, random_state=42)\n",
        "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Convert Data for XGBoost\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "dtest = xgb.DMatrix(X_test, label=y_test)\n",
        "\n",
        "# 6️⃣ Scale Features (Standardization)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Define Model Parameters\n",
        "params = study.best_params\n",
        "\n",
        "# 7️⃣ Train Models\n",
        "# Train XGBoost with Custom Focal Loss\n",
        "model = XGBClassifier(\n",
        "    objective=\"binary:logistic\",  # This ensures probability output\n",
        "    eval_metric=\"logloss\",\n",
        "    use_label_encoder=False,  # Prevents warnings\n",
        "    **params,  # Your tuned parameters\n",
        "    random_state=42\n",
        ")\n",
        "# model = xgb.train(params, dtrain, num_boost_round=100)\n",
        "model.fit(  X_train, y_train, eval_set=[(X_test, y_test)])\n",
        "\n",
        "\n",
        "# 9️⃣ Evaluate Models\n",
        "results = {}\n",
        "\n",
        "# Predictions\n",
        "# y_prob = model.predict(dtest)\n",
        "\n",
        "y_probs = model.predict_proba(X_test)[:, 1]\n",
        "precisions, recalls, thresholds = precision_recall_curve(y_test, y_probs)\n",
        "f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
        "best_threshold = thresholds[np.argmax(f1_scores)]\n",
        "\n",
        "print(f\"Optimal Threshold: {best_threshold:.4f}\")\n",
        "\n",
        "y_pred = (y_probs >= best_threshold).astype(int)\n",
        "\n",
        "# Evaluate Model\n",
        "metrics = {\n",
        "    \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "    \"Precision\": precision_score(y_test, y_pred),\n",
        "    \"Recall\": recall_score(y_test, y_pred),\n",
        "    \"F1 Score\": f1_score(y_test, y_pred),\n",
        "    \"AUC-ROC\": roc_auc_score(y_test, y_prob)\n",
        "}\n",
        "\n",
        "# Print Results\n",
        "print(\"\\n🔹 Model with Focal Loss (XGBoost)\")\n",
        "\n",
        "results[name] = metrics\n",
        "for metric, value in metrics.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n",
        "\n",
        "# Convert results to DataFrame and save\n",
        "results_df = pd.DataFrame(results).T\n",
        "results_df.to_csv(\"Fraud_Detection_Model_Results.csv\", index=True)\n",
        "\n",
        "print(\"\\n Fraud Detection Modeling Completed & Results Saved!\")\n",
        "\n",
        "# !pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cdJkcDhxC6k",
        "outputId": "e9d6cbe3-c1c2-44f8-cfe0-39e49870b6ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['xgb_model.pkl']"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "# Save the trained model\n",
        "joblib.dump(model, 'xgb_model.pkl')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJZsXGSu9MWT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
